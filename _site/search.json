[
  {
    "objectID": "SOFARI_Baseline.html",
    "href": "SOFARI_Baseline.html",
    "title": "Pain and function at baseline assessment of foot and ankle pathology: An analysis of the SOFARI Registry",
    "section": "",
    "text": "This analysis is to replicate a study describing the distribution of pain catastrophizing in patients presenting for surgical review of hip pathology (hampton2019?).\n\n\nThe study was reported according to the RECORD guidelines (Benchimol2015?) and companion checklist.\nThe analysis was conducted in RStudio IDE (RStudio 2024.12.0+467 “Kousa Dogwood” Release) using Rbase (base?), quarto (quarto?) and attached packages to perform the following;\n\nData import and preparation\nSample selection\nDescribe and address missingness\nData manipulation, modelling and visualisation of;\n\nPatient characteristics\nPathology characteristics (diagnosis)\nPatient reported outcomes\n\n\n\n\n\nLoad up required packages in advance. Citations are applied to each library at first use in the text. \n\n\nCode\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(\n  \"patchwork\",\n  \"car\",\n  \"corrplot\",\n  \"knitr\",\n  \"cardx\",\n  \"quarto\",\n  \"pROC\",\n  \"reshape\",\n  \"future\",\n  \"furrr\",\n  \"memoise\",\n  \"gargle\",\n  \"googledrive\",\n  \"googlesheets4\",\n  \"openxlsx2\",\n  \"readr\",\n  \"purrr\",\n  \"tidyverse\",\n  \"tidymodels\",\n  \"tidytext\",\n  \"stopwords\",\n  \"tictoc\",\n  \"lubridate\",\n  \"forcats\",\n  \"gt\",\n  \"consort\",\n  \"gtsummary\",\n  \"flextable\",\n  \"survival\",\n  \"ggplot2\",\n  \"ggdist\",\n  \"ggsurvfit\",\n  \"ggfortify\",\n  \"mice\",\n  \"marginaleffects\",\n  \"patchwork\",\n  \"naniar\",\n  \"quantreg\",\n  \"broom\",\n  \"broom.helpers\",\n  \"labelled\",\n  \"epoxy\",\n  \"broom.mixed\",\n  \"lme4\",\n  \"janitor\",\n  \"progressr\",\n  \"DT\",\n  install = TRUE,\n  update = FALSE\n)\n\n\n\n\n\n\nTable 1: Summary of package usage and citations\n\n\n\n\n\n\n\n\n\n\n\nPackage\nVersion\nCitation\n\n\n\n\nbase\n4.4.2\n(base?)\n\n\nbroom.helpers\n1.21.0\n(broomhelpers?)\n\n\nbroom.mixed\n0.2.9.6\n(broommixed?)\n\n\ncar\n3.1.3\n(car?)\n\n\ncardx\n0.2.5\n(cardx?)\n\n\nconsort\n1.2.2\n(consort?)\n\n\ncorrplot\n0.95\n(corrplot?)\n\n\ndistributional\n0.5.0\n(distributional?)\n\n\nDT\n0.33\n(DT?)\n\n\nepoxy\n1.0.0\n(epoxy?)\n\n\nflextable\n0.9.9\n(flextable?)\n\n\nfurrr\n0.3.1\n(furrr?)\n\n\nfuture\n1.67.0\n(future?)\n\n\ngargle\n1.5.2\n(gargle?)\n\n\nggdist\n3.3.3\n(ggdist2024?); (ggdist2025?)\n\n\nggfortify\n0.4.19\n(ggfortify2016?); (ggfortify2018?)\n\n\nggsurvfit\n1.1.0\n(ggsurvfit?)\n\n\nglue\n1.8.0\n(glue?)\n\n\ngt\n1.0.0\n(gt?)\n\n\ngtsummary\n2.3.0\n(gtsummary?)\n\n\njanitor\n2.2.1\n(janitor?)\n\n\nknitr\n1.50\n(knitr2014?); (knitr2015?); (knitr2025?)\n\n\nlabelled\n2.14.1\n(labelled?)\n\n\nlme4\n1.1.37\n(lme4?)\n\n\nmarginaleffects\n0.28.0\n(marginaleffects?)\n\n\nmemoise\n2.0.1\n(memoise?)\n\n\nmice\n3.18.0\n(mice?)\n\n\nnaniar\n1.1.0\n(naniar?)\n\n\nopenxlsx2\n1.18\n(openxlsx2?)\n\n\npacman\n0.5.1\n(pacman?)\n\n\npatchwork\n1.3.1\n(patchwork?)\n\n\npROC\n1.19.0.1\n(pROC?)\n\n\nprogressr\n0.15.1\n(progressr?)\n\n\nquantreg\n6.1\n(quantreg?)\n\n\nquarto\n1.5.0\n(quarto?)\n\n\nreshape\n0.8.10\n(reshape?)\n\n\nrmarkdown\n2.29\n(rmarkdown2018?); (rmarkdown2020?); (rmarkdown2024?)\n\n\nstopwords\n2.3\n(stopwords?)\n\n\nsurvival\n3.7.0\n(survival2000?); (survival2024?)\n\n\ntictoc\n1.2.1\n(tictoc?)\n\n\ntidymodels\n1.3.0\n(tidymodels?)\n\n\ntidytext\n0.4.3\n(tidytext?)\n\n\ntidyverse\n2.0.0\n(tidyverse?)\n\n\n\n\n\n\n\n\n\n\n\nPre-authorise access to registry datasets using the gargle package (v1.5.2) (gargle?).\n\n\n\nInclude a series of functions to call later in the file for processing data imports.\nFunction to retrieve files, using googledrive package(v2.1.1) (googledrive?).\n\n\nCode\nget_latest_snapshot &lt;- function(base_folder_id = base_folder_id1) {\n  tryCatch({\n    # List all folders in the base directory\n    folders &lt;- googledrive::drive_ls(as_id(base_folder_id), pattern = \"^\\\\d{8}$\")\n    \n    if(nrow(folders) == 0) {\n      stop(\"No dated folders found\")\n    }\n    \n    # Sort folders by name (date) in descending order\n    latest_folder &lt;- folders[order(folders$name, decreasing = TRUE),][1,]\n    \n    # Find the snapshot file in the latest folder\n    snapshot_file &lt;- googledrive::drive_ls(\n      latest_folder$id, \n      pattern = \"Registry data snapshot\\\\.xlsx$\"\n    )\n    \n    if(nrow(snapshot_file) == 0) {\n      stop(\"No snapshot file found in latest folder\")\n    }\n    \n    # Return both pieces of information as a list\n    return(list(\n      snapshot = snapshot_file,\n      folder_name = latest_folder$name\n    ))\n    \n  }, error = function(e) {\n    stop(paste(\"Error finding latest snapshot:\", e$message))\n  })\n}\n\n\nA general text cleaning function was constructed to apply during first import of raw data files, built on tidyverse (v2.0.0) (tidyverse-2?) and stringr (v1.5.1) (stringr-2?). The janitor package (v2.2.1) (janitor?) was utilised to clean column names in the resulting dataframe.\n\n\nCode\n# Generalized text cleaning function\nclean_text &lt;- function(text) {\n  text |&gt; \n    stringr::str_to_lower() |&gt;\n    stringr::str_squish() |&gt;\n    stringr::str_replace_all(\"\\\\.|\\\\. |\\\\: |\\\\, |w\\\\/\", \"; \") |&gt;\n    stringr::str_replace_all(\";+\", \"; \") |&gt;\n    stringr::str_remove_all(\"^;|;$\")\n}\n\n\n\n\nCode\nbind_and_clean &lt;- function(df1, df2, cols = NULL, clean_cols = NULL, clean_fn = clean_text) {\n  # Store the names of the input dataframes\n  df1_name &lt;- deparse(substitute(df1))\n  df2_name &lt;- deparse(substitute(df2))\n  \n  # Bind rows\n  result &lt;- bind_rows(df1, df2)\n  \n  # If cols is specified, select those columns, otherwise keep all columns\n  if (!is.null(cols)) {\n    result &lt;- result |&gt; dplyr::select(all_of(cols))\n  }\n  \n  # Apply text cleaning to specified columns\n  if (!is.null(clean_cols)) {\n    for (col in clean_cols) {\n      if (col %in% names(result)) {\n        result[[col]] &lt;- clean_fn(result[[col]])\n      } else {\n        warning(glue::glue(\"Column '{col}' not found in dataframe\"))\n      }\n    }\n  }\n  \n  # Remove the input dataframes from the parent environment\n  rm(list = c(df1_name, df2_name), envir = parent.frame())\n  \n  # Clean column names for consistency\n  result |&gt; janitor::clean_names(\n    case = \"big_camel\"\n  )\n}\n\n\n\n\nInclude a series of functions for calling later in the file to process sub-phases of converting clinical text stored in the registry to categories of pathology affecting the foot and ankle. The functions were built on tidyverse and stringr packages to manipulate data, future (v1.67.0) (future?) and furrr (v0.3.1) (furrr?) to enable distributed processing of the records. The progressr package (v0.15.1) (progressr?) was utlised to enable visual progress to be communicated during processing and memoise (v2.0.1) (memoise?)to cache processing results from batches of subsets of the registry dataset to enable distributed processing.\n\n\nCode\n# Enable parallel processing\nfuture::plan(multisession)\n\n# Configure progress reporting\nprogressr::handlers(\"progress\")\n\n# Create a shared cache (in memory or filesystem)\nshared_cache &lt;- memoise::cache_memory()\n\n# Memoize the target terms loading to match original format\nload_target_terms &lt;- memoise::memoise(function(sheet_url, sheet_name = \"DiagTerm\", range = \"A1:C\") {\n  terms &lt;- googlesheets4::range_read(\n    ss = sheet_url,\n    sheet = sheet_name,\n    range = range,\n    col_names = TRUE,\n    trim_ws = TRUE\n  ) |&gt; \n    mutate(TargetTerm = paste0(\"\\\\b\", stringr::str_escape(Term), \"\\\\b\"))\n  \n  list(\n    terms = terms,\n    pattern = str_c(terms$TargetTerm, collapse = \"|\")\n  )\n})\n\n# Target-Replacement Function\ncreate_replace_function &lt;- function(target_terms_df) {\n  function(string) {\n    # Find the matched term in target_terms_df\n    match &lt;- filter(target_terms_df, Term == string)\n    \n    # Check if a match is found\n    if (nrow(match) == 1) {\n      return(match$ReplaceTerm)\n    } else {\n      # Return the original string if no match is found\n      return(string)\n    }\n  }\n}\n\nclean_diagnosis_text &lt;- memoise::memoise (function(df) {\n  df |&gt; \n    dplyr::select(TreatmentID, DiagnosisRawFinal, DiagnosisRawPrelim) |&gt; \n    tidyr::unite(\"DiagnosisRaw\", c(DiagnosisRawFinal, DiagnosisRawPrelim), \n          na.rm = TRUE, remove = FALSE, sep = \"; \") |&gt; \n    filter(stringr::str_count(str_to_lower(DiagnosisRaw), \"\") &gt; 1) |&gt; \n    mutate(\n      DiagnosisRaw = stringr::str_squish(DiagnosisRaw),\n      DiagnosisRaw = stringr::str_replace_all(DiagnosisRaw, \"\\\\.|\\\\. |\\\\: |\\\\, |w\\\\/\", \";\"),\n      DiagnosisRaw = stringr::str_replace_all(DiagnosisRaw, \"\\\\#\", \"fracture\"),\n      DiagnosisRaw = stringr::str_replace_all(DiagnosisRaw, \";+\", \";\"),\n      DiagnosisRaw = stringr::str_trim(stringr::str_remove_all(DiagnosisRaw, \"^;|;$\"))\n    )\n})\n\n# Modified process_batch1 to maintain sequence integrity\nprocess_batch1 &lt;- function(batch_df) {\n  batch_df |&gt; \n    mutate(\n      DiagnosisRaw1 = stringr::str_replace_all(\n        str_to_lower(DiagnosisRaw), \n        \"\\\\bwith\\\\b|\\\\band\\\\b|\\\\bas well as\\\\b\", \";\"\n      ),\n      DiagnosisRaw1 = stringr::str_replace_all(DiagnosisRaw1, \"\\\\s+\", \" \"),\n      DiagnosisRaw1 = stringr::str_trim(DiagnosisRaw1)\n    ) |&gt; \n    tidyr::separate_rows(DiagnosisRaw1, sep = \";\") |&gt; \n    mutate(\n      DiagnosisRaw1 = stringr::str_trim(DiagnosisRaw1),\n      # Add row identifier before unnesting\n      SequenceID = row_number()\n    ) |&gt; \n    filter(nchar(DiagnosisRaw1) &gt; 0) |&gt;\n    tidytext::unnest_tokens(\n      output = Term,\n      input = DiagnosisRaw1,\n      token = \"regex\",\n      pattern = \"\\\\s+\",\n      format = \"text\",\n      to_lower = TRUE,\n      drop = FALSE\n    ) |&gt;\n    anti_join(stop_words, by = c(\"Term\" = \"word\")) |&gt;\n    mutate(\n      TermLength = stringr::str_length(Term),\n      # Maintain original ordering within each diagnosis\n      term_sequence = row_number()\n    ) |&gt;\n    group_by(TreatmentID, SequenceID) |&gt;\n    mutate(\n      term_count = n(),\n      term_position = row_number()\n    ) |&gt;\n    ungroup()\n}\n\n# Modified process_batch2 to preserve sequence information\nprocess_batch2 &lt;- function(batch_df, target_terms) {\n  replace_function &lt;- create_replace_function(target_terms$terms)\n  \n  batch_df |&gt; \n    mutate(\n      Term1 = stringr::str_replace_all(Term, target_terms$pattern, replace_function)\n    ) |&gt; \n    filter(\n      stringr::str_detect(\n        Term1, \n        \"\\\\d+(?!(?:st|nd|rd|th)\\\\b)|(left|right)\", \n        negate = TRUE\n      )\n    ) |&gt;\n    # Preserve grouping and sequence\n    arrange(TreatmentID, SequenceID, term_position)\n}\n\n# Modified tokenize_diagnosis to handle sequence preservation\ntokenize_diagnosis &lt;- memoise::memoise(function(df, stop_words = NULL, batch_size = 500, process_batch) {\n  if (is.null(stop_words)) {\n    stop_words &lt;- tidytext::get_stopwords()\n  }\n  \n  if (missing(process_batch)) {\n    stop(\"You must provide a process_batch function.\")\n  }\n  \n  # Add global identifier before splitting\n  df &lt;- df |&gt; mutate(global_id = row_number())\n  \n  # Split the data into batches\n  df_split &lt;- split(df, ceiling(seq_len(nrow(df)) / batch_size))\n  \n  # Process batches while maintaining order\n  furrr::future_map_dfr(df_split, process_batch, .progress = TRUE) |&gt;\n    arrange(global_id, term_position)\n})\n\n\n\n\nCode\n# Term replacement logic\napply_target_terms &lt;- memoise::memoise(function(df, target_terms, batch_size = 500, process_batch) {\n  # Ensure `process_batch` is provided\n  if (missing(process_batch)) {\n    stop(\"You must provide a process_batch function.\")\n  }\n  \n  # Split the data into batches\n  df_split &lt;- split(df, ceiling(seq_len(nrow(df)) / batch_size))\n  \n  # Process each batch using the provided `process_batch` function\n  furrr::future_map_dfr(df_split, ~process_batch(.x, target_terms), .progress = TRUE)\n})\n\n\n\n\nCode\n# Function to safely process diagnosis\nsafe_process_diagnosis &lt;- function(\n    snapshot_df,\n    target_terms_url,\n    stop_words = NULL,\n    batch_size = 1000,\n    tokenize_batch = process_batch1,\n    term_batch = process_batch2,\n    workers = 4\n    ) {    # Add workers parameter\n  \n  # Set up parallel processing\n  old_plan &lt;- plan(multisession, workers = workers)\n  on.exit(plan(old_plan), add = TRUE)  # Ensure we reset the plan when done\n  \n  # Set up progress handling\n  handlers(\"progress\")\n  \n  tryCatch({\n    with_progress({\n      p &lt;- progressor(steps = 4)\n      \n      # Load target terms\n      p(message = \"Loading target terms...\")\n      terms_data &lt;- load_target_terms(target_terms_url)\n      \n      # Process the diagnosis data with progress updates\n      p(message = \"Cleaning text...\")\n      cleaned_data &lt;- clean_diagnosis_text(snapshot_df)\n      \n      # Ensure stop_words is available\n      if (is.null(stop_words)) {\n        stop_words &lt;- tidytext::get_stopwords()\n      }\n      \n      # Create the tokenize batch function closure\n      tokenize_batch_fn &lt;- function(batch_df) {\n        process_batch1(batch_df)\n      }\n      \n      environment(tokenize_batch_fn)$stop_words &lt;- stop_words\n      \n      p(message = \"Tokenizing diagnosis...\")\n      tokenized_data &lt;- tokenize_diagnosis(\n        df = cleaned_data, \n        stop_words = stop_words,\n        batch_size = batch_size,\n        process_batch = tokenize_batch_fn\n      )\n      \n      p(message = \"Applying target terms...\")\n      processed_data &lt;- apply_target_terms(\n        df = tokenized_data, \n        target_terms = terms_data,\n        batch_size = batch_size,\n        process_batch = term_batch\n      )\n      \n      processed_data\n    })\n  }, error = function(e) {\n    message(\"Error in processing: \", e$message)\n    # Clean up any remaining connections or resources\n    future:::ClusterRegistry(\"stop\")\n    stop(e)\n  })\n}\n\n\nFunction to conduct categorisation of terms for pathology (diagnosis) stored in the registry.\n\n\nCode\n#' Categorize medical diagnoses with anatomical and pathological classifications\n#' @param df A dataframe containing Term2 columns\n#' @param remove_intermediate Logical, whether to remove intermediate processing columns\n#' @param use_parallel Logical, whether to use parallel processing for large datasets\n#' @param chunk_size Integer, number of rows to process in each parallel chunk\n#' @return A dataframe with new classification columns based on Term2 pattern matching\ncategorize_diagnosis &lt;- function(\n    df,\n    remove_intermediate = TRUE,\n    use_parallel = FALSE,\n    chunk_size = 1000\n    ) {\n  \n  # Input validation with more detailed error message\n  required_cols &lt;- c(\"Term2\")\n  if(!all(required_cols %in% names(df))) {\n    stop(\"Missing required column 'Term2'. Available columns are: \", \n         paste(names(df), collapse = \", \"))\n  }\n  \n  # Ensure df is a data.frame\n  df &lt;- as.data.frame(df)\n  \n  # Main processing function\n  process_chunk &lt;- function(chunk_df) {\n    # Ensure required packages are loaded in parallel context\n    require(dplyr)\n    require(stringr)\n    \n    # Convert chunk to data.frame to ensure consistent behavior\n    chunk_df &lt;- as.data.frame(chunk_df)\n    \n    chunk_df |&gt; \n      # Extract diagnosis side\n      mutate(\n        # Anatomical classifications\n        Ankle = if_else(str_detect(chunk_df$Term2, \"ankle|tibiotalar|\\\\bplafond\\\\b|dome|malleol*|weber|achilles|tendo-achilles|fibula|\\\\btibia\\\\b|gutter|perone*|syndesmo|gastrocnemius|talo-fibular|talofibular|calcaneofibular|calcaneo-fibular|gutter|(lateral|medial)\\\\s+ligament|tibia|deltoid|compartment.+syndrome\") & str_detect(chunk_df$Term2,\"(lateral|medial)\\\\s+collateral\\\\s+ligament\", negate = TRUE),1,0),\n        \n        Rearfoot = if_else(str_detect(chunk_df$Term2, \"\\\\btarsal\\\\b|\\\\btalar(?!\\\\s+dome)|talus|talonavic*|plantar|rearfoot|hindfoot|trigonum|hindfeet|tarsi|calcaneus|\\\\bcalcaneal\\\\b|heel|subtalar\"),1,0),\n        \n        Midfoot = if_else(str_detect(chunk_df$Term2, \"metatarsus|tarsometatarsal|tarso-metatarsal|\\\\bmetatarsal\\\\b|talonavicular|navicular|cuneiform|lisfranc|cuboid|midfoot|jones|chopart\"),1,0),\n        \n        Forefoot = if_else(str_detect(chunk_df$Term2, \"digit*|morton*|metatarsophalangeal|phalange*|phalanx|hallux|nail|forefoot|forefeet|bunionette|hallucis|onychomycosis|paronychia|bunion|hammertoe|claw|sesamoid\"),1,0),\n        \n        Foot = if_else(str_detect(chunk_df$Term2, \"\\\\bfeet\\\\b|\\\\bfoot\\\\b|cavovarus|equinovarus|equinus|pes|charcot|footdrop|neuropathy\"),1,0)\n      ) |&gt;\n      # Pathological classifications\n      mutate(\n        Arthritis = if_else(str_detect(chunk_df$Term2, \"psoria|arthritis|osteoarthritis|rheumatoid|gout|erosion|arthropathy\"),1,0),\n        \n        Injury = if_else(str_detect(chunk_df$Term2, \"injury|injuries|axial|impact|crush|rotation|inversion|forced|accident|tear|torn|ruptur|avulsion|fracture|defect|(osteochondral|chondral|cartilage).+lesion|sprain|haemarthrosis|disruption|wound|laceration|penetrating|hernia|maisonneuve\"), 1, 0),\n        \n        Deformity = if_else(str_detect(chunk_df$Term2, \"malalignment|deformit|angulation|contracture|contraction|\\\\bvalgus\\\\b|varus|planovalgus|valgoplanus|dysfunction|extension|adductus|crossover|hammer|claw|bunionette|bunion|interphalangeus|(relatively|significantly).+long|relative.+long\"),1,0),\n        \n        Metatarsalgia = if_else(str_detect(chunk_df$Term2, \"metatarsalgia|forefoot.+overload\"),1,0),\n        \n        SoftTissueDisorder = if_else(str_detect(chunk_df$Term2, \"tenosynovitis|enthesopathy|teno-synovitis|tendinopathy|tendinitis|tendonitis|tendinosis|fasciosis|fasciitis|sesamoiditis|arthrofibro|scar|tibialis posterior.+dysfunction|dysfunction tibialis posterior\"),1,0),\n        \n        Growth = if_else(str_detect(chunk_df$Term2, \"cyst|ganglion|neuroma|malformation|fibroma|tumour|accessory|ingrown|in_grown|coalition|(?&lt;!(?:chondral|osteochondral|cartilage)\\\\s)\\\\blesion\\\\b|xanthomas|osteoma|gioma|schwannoma|chondroma|lump|villonodular|callosity|corn|mass|\\\\b(non|mal|delayed)[-]?union|pseudo-articulation|bone.+loss|exostosis|spur|osteophyte|onychogryphosis|bipartite|neuroma|chondromatosis\"), 1, 0),\n        \n        Neural = if_else(str_detect(chunk_df$Term2, \"foot.+drop|footdrop|nerve|neuropathy|neural|sensory|charcot|motor|pain.+syndrome|tunnel.+syndrome|neuropathic|denervation\"),1,0),\n        \n        Infection = if_else(str_detect(chunk_df$Term2, \"infect|osteomyelitis|cellulitis|onychomycosis|ulcer|paronychia\"),1,0),\n        \n        Impingement = if_else(str_detect(chunk_df$Term2, \"impingement|stiffness|os.+trigonum\"),1,0),\n        \n        Instability = if_else(str_detect(chunk_df$Term2, \"disloc|unstable|sublux|instability|talar.+shift|widening|maisonneuve\"),1,0)\n      ) |&gt;\n      # Final classifications\n      mutate(\n        Other = if_else(rowSums(across(c(Arthritis:Instability))) &lt; 1 | str_detect(chunk_df$Term2,\"foreign.+(body|material)\"),1,0),\n        NegatePathology = if_else(str_detect(chunk_df$Term2, \"(?&lt;!ab?)normal|(?&lt;!(non|mal)-?)|nil.+pathology|\\\\bheal\\\\b|reduced|non-tender|unremarkable\"),0,1)\n      )\n  }\n  \n  # Process data based on parallel preference\n  if (use_parallel && nrow(df) &gt; chunk_size) {\n    # Ensure required packages are loaded in main session\n    require(future)\n    require(furrr)\n    \n    # Set up parallel processing\n    plan(multisession)\n    \n    # Create chunks with explicit data.frame conversion\n    chunks &lt;- split(df, ceiling(seq_len(nrow(df))/chunk_size))\n    chunks &lt;- lapply(chunks, as.data.frame)\n    \n    # Process chunks in parallel\n    df_processed &lt;- future_map_dfr(chunks, process_chunk, .progress = TRUE)\n  } else {\n    df_processed &lt;- process_chunk(df)\n  }\n  \n  return(df_processed)\n}\n\n# Create cached version\ncategorize_diagnosis_cached &lt;- memoise::memoise(categorize_diagnosis)\n\n\nConcatenated terms for each treatment record using tidyverse syntax. Generated a method to cumulatively concatenate terms within a treatment record that have been split into text sequences delimited by punctuation (e.g. “;”).\n\n\nCode\nconcatenate_diagnoses &lt;- function(data) {\n  # Sort the data by TreatmentID and SequenceRow in descending order\n  data %&gt;%\n    arrange(TreatmentID, desc(SequenceRow)) %&gt;%\n    group_by(TreatmentID) %&gt;%\n    mutate(\n      CumulativeTerm = accumulate(Term2, \n                                 .f = function(x, y) {\n                                   if (is.na(x)) y else paste(y, x, sep = \"; \")\n                                 }) %&gt;% \n        last()\n    ) %&gt;%\n    ungroup()\n}\n\n\n\n\nCode\nconcatenate_cumulative &lt;- function(SequenceRow, ProductCuml, Term2) {\n  # Create a dataframe to help with tracking\n  df &lt;- data.frame(\n    SequenceRow = SequenceRow, \n    ProductCuml = ProductCuml, \n    Term2 = Term2,\n    stringsAsFactors = FALSE\n  )\n  \n  # Sort by SequenceRow to ensure correct processing\n  df &lt;- df[order(df$SequenceRow), ]\n  \n  # Initialize result vector\n  result &lt;- character(length(SequenceRow))\n  \n  # Use accumulate to build up the terms\n  accumulated_result &lt;- purrr::accumulate(\n    1:nrow(df), \n    .init = list(\n      accumulated_terms = character(),\n      last_classified_term = NA_character_\n    ),\n    function(acc, i) {\n      # Current row details\n      current_term &lt;- df$Term2[i]\n      current_product_cuml &lt;- df$ProductCuml[i]\n      \n      # If current row is classified (ProductCuml &gt;= 1)\n      if (current_product_cuml &gt;= 1) {\n        # Concatenate all accumulated terms with current term\n        if (length(acc$accumulated_terms) &gt; 0) {\n          combined_term &lt;- str_c(\n            str_c(acc$accumulated_terms, collapse = \"; \"), \n            current_term, \n            sep = \"; \"\n          )\n        } else {\n          combined_term &lt;- current_term\n        }\n        \n        # Return updated state\n        list(\n          accumulated_terms = character(),\n          last_classified_term = combined_term\n        )\n      } else {\n        # Accumulate terms for rows with ProductCuml &lt; 1\n        list(\n          accumulated_terms = c(acc$accumulated_terms, current_term),\n          last_classified_term = acc$last_classified_term\n        )\n      }\n    }\n  )\n  \n  # Extract the last_classified_term for each row\n  result &lt;- sapply(accumulated_result[-1], `[[`, \"last_classified_term\")\n  \n  # Ensure result matches original input order\n  result[order(SequenceRow)] &lt;- result\n  \n  return(result)\n}"
  },
  {
    "objectID": "SOFARI_Baseline.html#reporting",
    "href": "SOFARI_Baseline.html#reporting",
    "title": "Pain and function at baseline assessment of foot and ankle pathology: An analysis of the SOFARI Registry",
    "section": "",
    "text": "The study was reported according to the RECORD guidelines (Benchimol2015?) and companion checklist.\nThe analysis was conducted in RStudio IDE (RStudio 2024.12.0+467 “Kousa Dogwood” Release) using Rbase (base?), quarto (quarto?) and attached packages to perform the following;\n\nData import and preparation\nSample selection\nDescribe and address missingness\nData manipulation, modelling and visualisation of;\n\nPatient characteristics\nPathology characteristics (diagnosis)\nPatient reported outcomes"
  },
  {
    "objectID": "SOFARI_Baseline.html#preparation",
    "href": "SOFARI_Baseline.html#preparation",
    "title": "Pain and function at baseline assessment of foot and ankle pathology: An analysis of the SOFARI Registry",
    "section": "",
    "text": "Load up required packages in advance. Citations are applied to each library at first use in the text. \n\n\nCode\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(\n  \"patchwork\",\n  \"car\",\n  \"corrplot\",\n  \"knitr\",\n  \"cardx\",\n  \"quarto\",\n  \"pROC\",\n  \"reshape\",\n  \"future\",\n  \"furrr\",\n  \"memoise\",\n  \"gargle\",\n  \"googledrive\",\n  \"googlesheets4\",\n  \"openxlsx2\",\n  \"readr\",\n  \"purrr\",\n  \"tidyverse\",\n  \"tidymodels\",\n  \"tidytext\",\n  \"stopwords\",\n  \"tictoc\",\n  \"lubridate\",\n  \"forcats\",\n  \"gt\",\n  \"consort\",\n  \"gtsummary\",\n  \"flextable\",\n  \"survival\",\n  \"ggplot2\",\n  \"ggdist\",\n  \"ggsurvfit\",\n  \"ggfortify\",\n  \"mice\",\n  \"marginaleffects\",\n  \"patchwork\",\n  \"naniar\",\n  \"quantreg\",\n  \"broom\",\n  \"broom.helpers\",\n  \"labelled\",\n  \"epoxy\",\n  \"broom.mixed\",\n  \"lme4\",\n  \"janitor\",\n  \"progressr\",\n  \"DT\",\n  install = TRUE,\n  update = FALSE\n)\n\n\n\n\n\n\nTable 1: Summary of package usage and citations\n\n\n\n\n\n\n\n\n\n\n\nPackage\nVersion\nCitation\n\n\n\n\nbase\n4.4.2\n(base?)\n\n\nbroom.helpers\n1.21.0\n(broomhelpers?)\n\n\nbroom.mixed\n0.2.9.6\n(broommixed?)\n\n\ncar\n3.1.3\n(car?)\n\n\ncardx\n0.2.5\n(cardx?)\n\n\nconsort\n1.2.2\n(consort?)\n\n\ncorrplot\n0.95\n(corrplot?)\n\n\ndistributional\n0.5.0\n(distributional?)\n\n\nDT\n0.33\n(DT?)\n\n\nepoxy\n1.0.0\n(epoxy?)\n\n\nflextable\n0.9.9\n(flextable?)\n\n\nfurrr\n0.3.1\n(furrr?)\n\n\nfuture\n1.67.0\n(future?)\n\n\ngargle\n1.5.2\n(gargle?)\n\n\nggdist\n3.3.3\n(ggdist2024?); (ggdist2025?)\n\n\nggfortify\n0.4.19\n(ggfortify2016?); (ggfortify2018?)\n\n\nggsurvfit\n1.1.0\n(ggsurvfit?)\n\n\nglue\n1.8.0\n(glue?)\n\n\ngt\n1.0.0\n(gt?)\n\n\ngtsummary\n2.3.0\n(gtsummary?)\n\n\njanitor\n2.2.1\n(janitor?)\n\n\nknitr\n1.50\n(knitr2014?); (knitr2015?); (knitr2025?)\n\n\nlabelled\n2.14.1\n(labelled?)\n\n\nlme4\n1.1.37\n(lme4?)\n\n\nmarginaleffects\n0.28.0\n(marginaleffects?)\n\n\nmemoise\n2.0.1\n(memoise?)\n\n\nmice\n3.18.0\n(mice?)\n\n\nnaniar\n1.1.0\n(naniar?)\n\n\nopenxlsx2\n1.18\n(openxlsx2?)\n\n\npacman\n0.5.1\n(pacman?)\n\n\npatchwork\n1.3.1\n(patchwork?)\n\n\npROC\n1.19.0.1\n(pROC?)\n\n\nprogressr\n0.15.1\n(progressr?)\n\n\nquantreg\n6.1\n(quantreg?)\n\n\nquarto\n1.5.0\n(quarto?)\n\n\nreshape\n0.8.10\n(reshape?)\n\n\nrmarkdown\n2.29\n(rmarkdown2018?); (rmarkdown2020?); (rmarkdown2024?)\n\n\nstopwords\n2.3\n(stopwords?)\n\n\nsurvival\n3.7.0\n(survival2000?); (survival2024?)\n\n\ntictoc\n1.2.1\n(tictoc?)\n\n\ntidymodels\n1.3.0\n(tidymodels?)\n\n\ntidytext\n0.4.3\n(tidytext?)\n\n\ntidyverse\n2.0.0\n(tidyverse?)"
  },
  {
    "objectID": "SOFARI_Baseline.html#authorisations",
    "href": "SOFARI_Baseline.html#authorisations",
    "title": "Pain and function at baseline assessment of foot and ankle pathology: An analysis of the SOFARI Registry",
    "section": "",
    "text": "Pre-authorise access to registry datasets using the gargle package (v1.5.2) (gargle?)."
  },
  {
    "objectID": "SOFARI_Baseline.html#functions-for-processing",
    "href": "SOFARI_Baseline.html#functions-for-processing",
    "title": "Pain and function at baseline assessment of foot and ankle pathology: An analysis of the SOFARI Registry",
    "section": "",
    "text": "Include a series of functions to call later in the file for processing data imports.\nFunction to retrieve files, using googledrive package(v2.1.1) (googledrive?).\n\n\nCode\nget_latest_snapshot &lt;- function(base_folder_id = base_folder_id1) {\n  tryCatch({\n    # List all folders in the base directory\n    folders &lt;- googledrive::drive_ls(as_id(base_folder_id), pattern = \"^\\\\d{8}$\")\n    \n    if(nrow(folders) == 0) {\n      stop(\"No dated folders found\")\n    }\n    \n    # Sort folders by name (date) in descending order\n    latest_folder &lt;- folders[order(folders$name, decreasing = TRUE),][1,]\n    \n    # Find the snapshot file in the latest folder\n    snapshot_file &lt;- googledrive::drive_ls(\n      latest_folder$id, \n      pattern = \"Registry data snapshot\\\\.xlsx$\"\n    )\n    \n    if(nrow(snapshot_file) == 0) {\n      stop(\"No snapshot file found in latest folder\")\n    }\n    \n    # Return both pieces of information as a list\n    return(list(\n      snapshot = snapshot_file,\n      folder_name = latest_folder$name\n    ))\n    \n  }, error = function(e) {\n    stop(paste(\"Error finding latest snapshot:\", e$message))\n  })\n}\n\n\nA general text cleaning function was constructed to apply during first import of raw data files, built on tidyverse (v2.0.0) (tidyverse-2?) and stringr (v1.5.1) (stringr-2?). The janitor package (v2.2.1) (janitor?) was utilised to clean column names in the resulting dataframe.\n\n\nCode\n# Generalized text cleaning function\nclean_text &lt;- function(text) {\n  text |&gt; \n    stringr::str_to_lower() |&gt;\n    stringr::str_squish() |&gt;\n    stringr::str_replace_all(\"\\\\.|\\\\. |\\\\: |\\\\, |w\\\\/\", \"; \") |&gt;\n    stringr::str_replace_all(\";+\", \"; \") |&gt;\n    stringr::str_remove_all(\"^;|;$\")\n}\n\n\n\n\nCode\nbind_and_clean &lt;- function(df1, df2, cols = NULL, clean_cols = NULL, clean_fn = clean_text) {\n  # Store the names of the input dataframes\n  df1_name &lt;- deparse(substitute(df1))\n  df2_name &lt;- deparse(substitute(df2))\n  \n  # Bind rows\n  result &lt;- bind_rows(df1, df2)\n  \n  # If cols is specified, select those columns, otherwise keep all columns\n  if (!is.null(cols)) {\n    result &lt;- result |&gt; dplyr::select(all_of(cols))\n  }\n  \n  # Apply text cleaning to specified columns\n  if (!is.null(clean_cols)) {\n    for (col in clean_cols) {\n      if (col %in% names(result)) {\n        result[[col]] &lt;- clean_fn(result[[col]])\n      } else {\n        warning(glue::glue(\"Column '{col}' not found in dataframe\"))\n      }\n    }\n  }\n  \n  # Remove the input dataframes from the parent environment\n  rm(list = c(df1_name, df2_name), envir = parent.frame())\n  \n  # Clean column names for consistency\n  result |&gt; janitor::clean_names(\n    case = \"big_camel\"\n  )\n}\n\n\n\n\nInclude a series of functions for calling later in the file to process sub-phases of converting clinical text stored in the registry to categories of pathology affecting the foot and ankle. The functions were built on tidyverse and stringr packages to manipulate data, future (v1.67.0) (future?) and furrr (v0.3.1) (furrr?) to enable distributed processing of the records. The progressr package (v0.15.1) (progressr?) was utlised to enable visual progress to be communicated during processing and memoise (v2.0.1) (memoise?)to cache processing results from batches of subsets of the registry dataset to enable distributed processing.\n\n\nCode\n# Enable parallel processing\nfuture::plan(multisession)\n\n# Configure progress reporting\nprogressr::handlers(\"progress\")\n\n# Create a shared cache (in memory or filesystem)\nshared_cache &lt;- memoise::cache_memory()\n\n# Memoize the target terms loading to match original format\nload_target_terms &lt;- memoise::memoise(function(sheet_url, sheet_name = \"DiagTerm\", range = \"A1:C\") {\n  terms &lt;- googlesheets4::range_read(\n    ss = sheet_url,\n    sheet = sheet_name,\n    range = range,\n    col_names = TRUE,\n    trim_ws = TRUE\n  ) |&gt; \n    mutate(TargetTerm = paste0(\"\\\\b\", stringr::str_escape(Term), \"\\\\b\"))\n  \n  list(\n    terms = terms,\n    pattern = str_c(terms$TargetTerm, collapse = \"|\")\n  )\n})\n\n# Target-Replacement Function\ncreate_replace_function &lt;- function(target_terms_df) {\n  function(string) {\n    # Find the matched term in target_terms_df\n    match &lt;- filter(target_terms_df, Term == string)\n    \n    # Check if a match is found\n    if (nrow(match) == 1) {\n      return(match$ReplaceTerm)\n    } else {\n      # Return the original string if no match is found\n      return(string)\n    }\n  }\n}\n\nclean_diagnosis_text &lt;- memoise::memoise (function(df) {\n  df |&gt; \n    dplyr::select(TreatmentID, DiagnosisRawFinal, DiagnosisRawPrelim) |&gt; \n    tidyr::unite(\"DiagnosisRaw\", c(DiagnosisRawFinal, DiagnosisRawPrelim), \n          na.rm = TRUE, remove = FALSE, sep = \"; \") |&gt; \n    filter(stringr::str_count(str_to_lower(DiagnosisRaw), \"\") &gt; 1) |&gt; \n    mutate(\n      DiagnosisRaw = stringr::str_squish(DiagnosisRaw),\n      DiagnosisRaw = stringr::str_replace_all(DiagnosisRaw, \"\\\\.|\\\\. |\\\\: |\\\\, |w\\\\/\", \";\"),\n      DiagnosisRaw = stringr::str_replace_all(DiagnosisRaw, \"\\\\#\", \"fracture\"),\n      DiagnosisRaw = stringr::str_replace_all(DiagnosisRaw, \";+\", \";\"),\n      DiagnosisRaw = stringr::str_trim(stringr::str_remove_all(DiagnosisRaw, \"^;|;$\"))\n    )\n})\n\n# Modified process_batch1 to maintain sequence integrity\nprocess_batch1 &lt;- function(batch_df) {\n  batch_df |&gt; \n    mutate(\n      DiagnosisRaw1 = stringr::str_replace_all(\n        str_to_lower(DiagnosisRaw), \n        \"\\\\bwith\\\\b|\\\\band\\\\b|\\\\bas well as\\\\b\", \";\"\n      ),\n      DiagnosisRaw1 = stringr::str_replace_all(DiagnosisRaw1, \"\\\\s+\", \" \"),\n      DiagnosisRaw1 = stringr::str_trim(DiagnosisRaw1)\n    ) |&gt; \n    tidyr::separate_rows(DiagnosisRaw1, sep = \";\") |&gt; \n    mutate(\n      DiagnosisRaw1 = stringr::str_trim(DiagnosisRaw1),\n      # Add row identifier before unnesting\n      SequenceID = row_number()\n    ) |&gt; \n    filter(nchar(DiagnosisRaw1) &gt; 0) |&gt;\n    tidytext::unnest_tokens(\n      output = Term,\n      input = DiagnosisRaw1,\n      token = \"regex\",\n      pattern = \"\\\\s+\",\n      format = \"text\",\n      to_lower = TRUE,\n      drop = FALSE\n    ) |&gt;\n    anti_join(stop_words, by = c(\"Term\" = \"word\")) |&gt;\n    mutate(\n      TermLength = stringr::str_length(Term),\n      # Maintain original ordering within each diagnosis\n      term_sequence = row_number()\n    ) |&gt;\n    group_by(TreatmentID, SequenceID) |&gt;\n    mutate(\n      term_count = n(),\n      term_position = row_number()\n    ) |&gt;\n    ungroup()\n}\n\n# Modified process_batch2 to preserve sequence information\nprocess_batch2 &lt;- function(batch_df, target_terms) {\n  replace_function &lt;- create_replace_function(target_terms$terms)\n  \n  batch_df |&gt; \n    mutate(\n      Term1 = stringr::str_replace_all(Term, target_terms$pattern, replace_function)\n    ) |&gt; \n    filter(\n      stringr::str_detect(\n        Term1, \n        \"\\\\d+(?!(?:st|nd|rd|th)\\\\b)|(left|right)\", \n        negate = TRUE\n      )\n    ) |&gt;\n    # Preserve grouping and sequence\n    arrange(TreatmentID, SequenceID, term_position)\n}\n\n# Modified tokenize_diagnosis to handle sequence preservation\ntokenize_diagnosis &lt;- memoise::memoise(function(df, stop_words = NULL, batch_size = 500, process_batch) {\n  if (is.null(stop_words)) {\n    stop_words &lt;- tidytext::get_stopwords()\n  }\n  \n  if (missing(process_batch)) {\n    stop(\"You must provide a process_batch function.\")\n  }\n  \n  # Add global identifier before splitting\n  df &lt;- df |&gt; mutate(global_id = row_number())\n  \n  # Split the data into batches\n  df_split &lt;- split(df, ceiling(seq_len(nrow(df)) / batch_size))\n  \n  # Process batches while maintaining order\n  furrr::future_map_dfr(df_split, process_batch, .progress = TRUE) |&gt;\n    arrange(global_id, term_position)\n})\n\n\n\n\nCode\n# Term replacement logic\napply_target_terms &lt;- memoise::memoise(function(df, target_terms, batch_size = 500, process_batch) {\n  # Ensure `process_batch` is provided\n  if (missing(process_batch)) {\n    stop(\"You must provide a process_batch function.\")\n  }\n  \n  # Split the data into batches\n  df_split &lt;- split(df, ceiling(seq_len(nrow(df)) / batch_size))\n  \n  # Process each batch using the provided `process_batch` function\n  furrr::future_map_dfr(df_split, ~process_batch(.x, target_terms), .progress = TRUE)\n})\n\n\n\n\nCode\n# Function to safely process diagnosis\nsafe_process_diagnosis &lt;- function(\n    snapshot_df,\n    target_terms_url,\n    stop_words = NULL,\n    batch_size = 1000,\n    tokenize_batch = process_batch1,\n    term_batch = process_batch2,\n    workers = 4\n    ) {    # Add workers parameter\n  \n  # Set up parallel processing\n  old_plan &lt;- plan(multisession, workers = workers)\n  on.exit(plan(old_plan), add = TRUE)  # Ensure we reset the plan when done\n  \n  # Set up progress handling\n  handlers(\"progress\")\n  \n  tryCatch({\n    with_progress({\n      p &lt;- progressor(steps = 4)\n      \n      # Load target terms\n      p(message = \"Loading target terms...\")\n      terms_data &lt;- load_target_terms(target_terms_url)\n      \n      # Process the diagnosis data with progress updates\n      p(message = \"Cleaning text...\")\n      cleaned_data &lt;- clean_diagnosis_text(snapshot_df)\n      \n      # Ensure stop_words is available\n      if (is.null(stop_words)) {\n        stop_words &lt;- tidytext::get_stopwords()\n      }\n      \n      # Create the tokenize batch function closure\n      tokenize_batch_fn &lt;- function(batch_df) {\n        process_batch1(batch_df)\n      }\n      \n      environment(tokenize_batch_fn)$stop_words &lt;- stop_words\n      \n      p(message = \"Tokenizing diagnosis...\")\n      tokenized_data &lt;- tokenize_diagnosis(\n        df = cleaned_data, \n        stop_words = stop_words,\n        batch_size = batch_size,\n        process_batch = tokenize_batch_fn\n      )\n      \n      p(message = \"Applying target terms...\")\n      processed_data &lt;- apply_target_terms(\n        df = tokenized_data, \n        target_terms = terms_data,\n        batch_size = batch_size,\n        process_batch = term_batch\n      )\n      \n      processed_data\n    })\n  }, error = function(e) {\n    message(\"Error in processing: \", e$message)\n    # Clean up any remaining connections or resources\n    future:::ClusterRegistry(\"stop\")\n    stop(e)\n  })\n}\n\n\nFunction to conduct categorisation of terms for pathology (diagnosis) stored in the registry.\n\n\nCode\n#' Categorize medical diagnoses with anatomical and pathological classifications\n#' @param df A dataframe containing Term2 columns\n#' @param remove_intermediate Logical, whether to remove intermediate processing columns\n#' @param use_parallel Logical, whether to use parallel processing for large datasets\n#' @param chunk_size Integer, number of rows to process in each parallel chunk\n#' @return A dataframe with new classification columns based on Term2 pattern matching\ncategorize_diagnosis &lt;- function(\n    df,\n    remove_intermediate = TRUE,\n    use_parallel = FALSE,\n    chunk_size = 1000\n    ) {\n  \n  # Input validation with more detailed error message\n  required_cols &lt;- c(\"Term2\")\n  if(!all(required_cols %in% names(df))) {\n    stop(\"Missing required column 'Term2'. Available columns are: \", \n         paste(names(df), collapse = \", \"))\n  }\n  \n  # Ensure df is a data.frame\n  df &lt;- as.data.frame(df)\n  \n  # Main processing function\n  process_chunk &lt;- function(chunk_df) {\n    # Ensure required packages are loaded in parallel context\n    require(dplyr)\n    require(stringr)\n    \n    # Convert chunk to data.frame to ensure consistent behavior\n    chunk_df &lt;- as.data.frame(chunk_df)\n    \n    chunk_df |&gt; \n      # Extract diagnosis side\n      mutate(\n        # Anatomical classifications\n        Ankle = if_else(str_detect(chunk_df$Term2, \"ankle|tibiotalar|\\\\bplafond\\\\b|dome|malleol*|weber|achilles|tendo-achilles|fibula|\\\\btibia\\\\b|gutter|perone*|syndesmo|gastrocnemius|talo-fibular|talofibular|calcaneofibular|calcaneo-fibular|gutter|(lateral|medial)\\\\s+ligament|tibia|deltoid|compartment.+syndrome\") & str_detect(chunk_df$Term2,\"(lateral|medial)\\\\s+collateral\\\\s+ligament\", negate = TRUE),1,0),\n        \n        Rearfoot = if_else(str_detect(chunk_df$Term2, \"\\\\btarsal\\\\b|\\\\btalar(?!\\\\s+dome)|talus|talonavic*|plantar|rearfoot|hindfoot|trigonum|hindfeet|tarsi|calcaneus|\\\\bcalcaneal\\\\b|heel|subtalar\"),1,0),\n        \n        Midfoot = if_else(str_detect(chunk_df$Term2, \"metatarsus|tarsometatarsal|tarso-metatarsal|\\\\bmetatarsal\\\\b|talonavicular|navicular|cuneiform|lisfranc|cuboid|midfoot|jones|chopart\"),1,0),\n        \n        Forefoot = if_else(str_detect(chunk_df$Term2, \"digit*|morton*|metatarsophalangeal|phalange*|phalanx|hallux|nail|forefoot|forefeet|bunionette|hallucis|onychomycosis|paronychia|bunion|hammertoe|claw|sesamoid\"),1,0),\n        \n        Foot = if_else(str_detect(chunk_df$Term2, \"\\\\bfeet\\\\b|\\\\bfoot\\\\b|cavovarus|equinovarus|equinus|pes|charcot|footdrop|neuropathy\"),1,0)\n      ) |&gt;\n      # Pathological classifications\n      mutate(\n        Arthritis = if_else(str_detect(chunk_df$Term2, \"psoria|arthritis|osteoarthritis|rheumatoid|gout|erosion|arthropathy\"),1,0),\n        \n        Injury = if_else(str_detect(chunk_df$Term2, \"injury|injuries|axial|impact|crush|rotation|inversion|forced|accident|tear|torn|ruptur|avulsion|fracture|defect|(osteochondral|chondral|cartilage).+lesion|sprain|haemarthrosis|disruption|wound|laceration|penetrating|hernia|maisonneuve\"), 1, 0),\n        \n        Deformity = if_else(str_detect(chunk_df$Term2, \"malalignment|deformit|angulation|contracture|contraction|\\\\bvalgus\\\\b|varus|planovalgus|valgoplanus|dysfunction|extension|adductus|crossover|hammer|claw|bunionette|bunion|interphalangeus|(relatively|significantly).+long|relative.+long\"),1,0),\n        \n        Metatarsalgia = if_else(str_detect(chunk_df$Term2, \"metatarsalgia|forefoot.+overload\"),1,0),\n        \n        SoftTissueDisorder = if_else(str_detect(chunk_df$Term2, \"tenosynovitis|enthesopathy|teno-synovitis|tendinopathy|tendinitis|tendonitis|tendinosis|fasciosis|fasciitis|sesamoiditis|arthrofibro|scar|tibialis posterior.+dysfunction|dysfunction tibialis posterior\"),1,0),\n        \n        Growth = if_else(str_detect(chunk_df$Term2, \"cyst|ganglion|neuroma|malformation|fibroma|tumour|accessory|ingrown|in_grown|coalition|(?&lt;!(?:chondral|osteochondral|cartilage)\\\\s)\\\\blesion\\\\b|xanthomas|osteoma|gioma|schwannoma|chondroma|lump|villonodular|callosity|corn|mass|\\\\b(non|mal|delayed)[-]?union|pseudo-articulation|bone.+loss|exostosis|spur|osteophyte|onychogryphosis|bipartite|neuroma|chondromatosis\"), 1, 0),\n        \n        Neural = if_else(str_detect(chunk_df$Term2, \"foot.+drop|footdrop|nerve|neuropathy|neural|sensory|charcot|motor|pain.+syndrome|tunnel.+syndrome|neuropathic|denervation\"),1,0),\n        \n        Infection = if_else(str_detect(chunk_df$Term2, \"infect|osteomyelitis|cellulitis|onychomycosis|ulcer|paronychia\"),1,0),\n        \n        Impingement = if_else(str_detect(chunk_df$Term2, \"impingement|stiffness|os.+trigonum\"),1,0),\n        \n        Instability = if_else(str_detect(chunk_df$Term2, \"disloc|unstable|sublux|instability|talar.+shift|widening|maisonneuve\"),1,0)\n      ) |&gt;\n      # Final classifications\n      mutate(\n        Other = if_else(rowSums(across(c(Arthritis:Instability))) &lt; 1 | str_detect(chunk_df$Term2,\"foreign.+(body|material)\"),1,0),\n        NegatePathology = if_else(str_detect(chunk_df$Term2, \"(?&lt;!ab?)normal|(?&lt;!(non|mal)-?)|nil.+pathology|\\\\bheal\\\\b|reduced|non-tender|unremarkable\"),0,1)\n      )\n  }\n  \n  # Process data based on parallel preference\n  if (use_parallel && nrow(df) &gt; chunk_size) {\n    # Ensure required packages are loaded in main session\n    require(future)\n    require(furrr)\n    \n    # Set up parallel processing\n    plan(multisession)\n    \n    # Create chunks with explicit data.frame conversion\n    chunks &lt;- split(df, ceiling(seq_len(nrow(df))/chunk_size))\n    chunks &lt;- lapply(chunks, as.data.frame)\n    \n    # Process chunks in parallel\n    df_processed &lt;- future_map_dfr(chunks, process_chunk, .progress = TRUE)\n  } else {\n    df_processed &lt;- process_chunk(df)\n  }\n  \n  return(df_processed)\n}\n\n# Create cached version\ncategorize_diagnosis_cached &lt;- memoise::memoise(categorize_diagnosis)\n\n\nConcatenated terms for each treatment record using tidyverse syntax. Generated a method to cumulatively concatenate terms within a treatment record that have been split into text sequences delimited by punctuation (e.g. “;”).\n\n\nCode\nconcatenate_diagnoses &lt;- function(data) {\n  # Sort the data by TreatmentID and SequenceRow in descending order\n  data %&gt;%\n    arrange(TreatmentID, desc(SequenceRow)) %&gt;%\n    group_by(TreatmentID) %&gt;%\n    mutate(\n      CumulativeTerm = accumulate(Term2, \n                                 .f = function(x, y) {\n                                   if (is.na(x)) y else paste(y, x, sep = \"; \")\n                                 }) %&gt;% \n        last()\n    ) %&gt;%\n    ungroup()\n}\n\n\n\n\nCode\nconcatenate_cumulative &lt;- function(SequenceRow, ProductCuml, Term2) {\n  # Create a dataframe to help with tracking\n  df &lt;- data.frame(\n    SequenceRow = SequenceRow, \n    ProductCuml = ProductCuml, \n    Term2 = Term2,\n    stringsAsFactors = FALSE\n  )\n  \n  # Sort by SequenceRow to ensure correct processing\n  df &lt;- df[order(df$SequenceRow), ]\n  \n  # Initialize result vector\n  result &lt;- character(length(SequenceRow))\n  \n  # Use accumulate to build up the terms\n  accumulated_result &lt;- purrr::accumulate(\n    1:nrow(df), \n    .init = list(\n      accumulated_terms = character(),\n      last_classified_term = NA_character_\n    ),\n    function(acc, i) {\n      # Current row details\n      current_term &lt;- df$Term2[i]\n      current_product_cuml &lt;- df$ProductCuml[i]\n      \n      # If current row is classified (ProductCuml &gt;= 1)\n      if (current_product_cuml &gt;= 1) {\n        # Concatenate all accumulated terms with current term\n        if (length(acc$accumulated_terms) &gt; 0) {\n          combined_term &lt;- str_c(\n            str_c(acc$accumulated_terms, collapse = \"; \"), \n            current_term, \n            sep = \"; \"\n          )\n        } else {\n          combined_term &lt;- current_term\n        }\n        \n        # Return updated state\n        list(\n          accumulated_terms = character(),\n          last_classified_term = combined_term\n        )\n      } else {\n        # Accumulate terms for rows with ProductCuml &lt; 1\n        list(\n          accumulated_terms = c(acc$accumulated_terms, current_term),\n          last_classified_term = acc$last_classified_term\n        )\n      }\n    }\n  )\n  \n  # Extract the last_classified_term for each row\n  result &lt;- sapply(accumulated_result[-1], `[[`, \"last_classified_term\")\n  \n  # Ensure result matches original input order\n  result[order(SequenceRow)] &lt;- result\n  \n  return(result)\n}"
  },
  {
    "objectID": "SOFARI_Baseline.html#abstract",
    "href": "SOFARI_Baseline.html#abstract",
    "title": "Pain and function at baseline assessment of foot and ankle pathology: An analysis of the SOFARI Registry",
    "section": "2.1 Abstract",
    "text": "2.1 Abstract\n\nPurpose:\nMethods:\nResults: Include geographic region and timeframe\nConclusion:"
  },
  {
    "objectID": "SOFARI_Baseline.html#record-1.1-data-type",
    "href": "SOFARI_Baseline.html#record-1.1-data-type",
    "title": "Pain and function at baseline assessment of foot and ankle pathology: An analysis of the SOFARI Registry",
    "section": "2.2 RECORD [1.1] Data Type",
    "text": "2.2 RECORD [1.1] Data Type\n\nData type included in Title."
  },
  {
    "objectID": "SOFARI_Baseline.html#record-1.2-geography-and-timeframe",
    "href": "SOFARI_Baseline.html#record-1.2-geography-and-timeframe",
    "title": "Pain and function at baseline assessment of foot and ankle pathology: An analysis of the SOFARI Registry",
    "section": "2.3 RECORD [1.2] Geography and Timeframe",
    "text": "2.3 RECORD [1.2] Geography and Timeframe\n\nIncluded in abstract."
  },
  {
    "objectID": "SOFARI_Baseline.html#record-1.3-data-linkage",
    "href": "SOFARI_Baseline.html#record-1.3-data-linkage",
    "title": "Pain and function at baseline assessment of foot and ankle pathology: An analysis of the SOFARI Registry",
    "section": "2.4 RECORD [1.3] Data Linkage",
    "text": "2.4 RECORD [1.3] Data Linkage\n\nNo data linkage to another data was performed for this analysis."
  },
  {
    "objectID": "SOFARI_Baseline.html#record-2-backgroundrationale",
    "href": "SOFARI_Baseline.html#record-2-backgroundrationale",
    "title": "Pain and function at baseline assessment of foot and ankle pathology: An analysis of the SOFARI Registry",
    "section": "2.5 RECORD [2] Background/rationale",
    "text": "2.5 RECORD [2] Background/rationale"
  },
  {
    "objectID": "SOFARI_Baseline.html#record-3-objectives",
    "href": "SOFARI_Baseline.html#record-3-objectives",
    "title": "Pain and function at baseline assessment of foot and ankle pathology: An analysis of the SOFARI Registry",
    "section": "2.6 RECORD [3] Objectives",
    "text": "2.6 RECORD [3] Objectives\n\nPICOS question format\n\n\n\nTable 2: Questions presented in PICOS format\n\n\n\n\n\nComponent\nQuestion 1\nComments\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.6.1 Hypotheses\nClinical and statistical hypotheses presented in tabular format\n\n\n\nTable 3: Clinical and statistical hypotheses for question 1 and 2\n\n\n\n\n\nCol1\nCol2\nCol3"
  },
  {
    "objectID": "SOFARI_Baseline.html#record-4-study-design",
    "href": "SOFARI_Baseline.html#record-4-study-design",
    "title": "Pain and function at baseline assessment of foot and ankle pathology: An analysis of the SOFARI Registry",
    "section": "3.1 RECORD [4] Study design",
    "text": "3.1 RECORD [4] Study design\n\nCross-sectional analysis of registry data."
  },
  {
    "objectID": "SOFARI_Baseline.html#record-5-setting",
    "href": "SOFARI_Baseline.html#record-5-setting",
    "title": "Pain and function at baseline assessment of foot and ankle pathology: An analysis of the SOFARI Registry",
    "section": "3.2 RECORD [5] Setting",
    "text": "3.2 RECORD [5] Setting\n\nThe SOFARI (Sydney Orthopaedic Foot and Ankle Research Institute) registry is a multi-site system based in Sydney, Australia. It commenced recruitment with one specialist in Jun-2020 and was expanded sequentially to three other specialists by Aug-2021.\nPatients were recruited in an opt-out consent model through electronic communication (sms, email) at the time of their initial consultation with their surgeon. Recruitment and data collection into the registry for the present analysis spans 6-Jun-2020 to 31-Jan-2025."
  },
  {
    "objectID": "SOFARI_Baseline.html#record-8-data-sourcesmeasurement",
    "href": "SOFARI_Baseline.html#record-8-data-sourcesmeasurement",
    "title": "Pain and function at baseline assessment of foot and ankle pathology: An analysis of the SOFARI Registry",
    "section": "3.3 RECORD [8] Data sources/measurement",
    "text": "3.3 RECORD [8] Data sources/measurement\n\nData was sourced directly from the SOFARI registry. Patient and treatment information were entered into the database through the registry interface and compiled into a data cube (snapshot) every quarter. Complications and adverse events captured into an online form (QuestionPro, USA) and linked using record identifier codes. Patient-reported outcomes were collected from the patient through electronic communication (sms, email) of a form link specific to baseline assessment and captured into an online form (QuestionPro, USA) for each questionnaire of interest. PROMs data were also linked back to patient and treatment infromation using record identifier codes.\n\n3.3.1 Data Import and Preparation\nData was retrieved and formatted using openxlsx (openxlsx2?) to retrieve static snapshot files and googlesheets4 (v1.1.1) (googlesheets4?) to retrieve live database tables. Text and code output were integrated using the epoxy package (v1.0.0) (epoxy?).\nSource files were specified and stored as global variables to call on in further functions.\nRead in complication tables, then combine and clean the text description of complications as required.\n\n\nCode\n# Authenticate for sheets using the same token\ngs4_auth(token = drive_token())\n\nComplicTable1 &lt;- googlesheets4::read_sheet(\n  ss = SheetIDs$Complic1,\n  sheet = \"Complications\",\n  range = \"A2:AD\",\n  col_names = TRUE,\n  col_types = \"cccTlnicicccccccccccicccccDccD\"\n  )\n\nComplicTable2 &lt;- range_read(\n  ss = SheetIDs$Complic2,\n  sheet = \"Complications\",\n  range = \"A2:AD\",\n  col_names = TRUE,\n  col_types = \"cccTlnicicccccccccccicccccDccD\"\n  )\n\n# Complication Table\nMasterComplic &lt;- bind_and_clean(\n  df1 = ComplicTable1, \n  df2 = ComplicTable2, \n  cols = c(\n    \"TreatmentID\", \n    \"ComplicationID\", \n    \"ComplicationOccurrence\",\n    \"ComplicationNature\", \n    \"DateOfOccurrence\",\n    \"ComplicationTreatmentOffered\",\n    \"DateReoperation\"),\n  clean_cols = \"ComplicationNature\",\n  clean_fn = clean_text  # Pass the function directly\n)\n\n\nRead in patient tables, then combine and clean the text columns as required.\n\n\nCode\n# Authenticate for sheets using the same token\ngs4_auth(token = drive_token())\n\nPatientTable1 &lt;- range_read(\n  ss = SheetIDs$Patient1,\n  sheet = \"Patient\",\n  col_names = c(\n  \"PatientCreationDate\",\n  \"PatientID\",\n  \"LastName\",\n  \"FirstName\",\n  \"AlternateID\",\n  \"DateOfBirth\",\n  \"Sex\",\n  \"RegistryStatus\",\n  \"RegistryStatusNotes\",\n  \"DateRegistryStatus\",\n  \"NotificationMethod\",\n  \"NoTreatmentRecords\",\n  \"Email\",\n  \"Phone\",\n  \"Postcode\",\n  \"PatientRegistrationStatus\",\n  \"DatePatientRegistration\",\n  \"TrueNoTreatmentRecords\"\n),\nrange = \"A6:R\",\ncol_types = \"DccccDcccTciccccTi\"\n)\n\nPatientTable2 &lt;- range_read(\n  ss = SheetIDs$Patient2,\n  sheet = \"Patient\",\n  col_names = c(\n  \"PatientCreationDate\",\n  \"PatientID\",\n  \"LastName\",\n  \"FirstName\",\n  \"AlternateID\",\n  \"DateOfBirth\",\n  \"Sex\",\n  \"RegistryStatus\",\n  \"RegistryStatusNotes\",\n  \"DateRegistryStatus\",\n  \"NotificationMethod\",\n  \"NoTreatmentRecords\",\n  \"Email\",\n  \"Phone\",\n  \"Postcode\",\n  \"PatientRegistrationStatus\",\n  \"DatePatientRegistration\",\n  \"TrueNoTreatmentRecords\"\n),\nrange = \"A6:R\",\ncol_types = \"DccccDcccTciccccTi\")\n\n\nMasterPatient &lt;- bind_rows(\n  PatientTable1,\n  PatientTable2\n) |&gt; mutate(\n  AlternateID2 = stringr::str_remove(AlternateID,\"MS1|MS2\")\n) |&gt; group_by(\n  PatientID\n) |&gt; mutate(\n  RecordNum = row_number()\n) |&gt; ungroup()\n\nrm(PatientTable1,\n  PatientTable2\n)\n\n\nProcess the registry snapshot by retrieving the file and use tidyverse to add columns, recode existing columns and create an additional identifier using tidyr (v1.3.1) (tidyr?), representing the patient and their side, to track multiple treatments for each limb. Dates were reformatted to a form appropriate for analysis using lubridate (v1.9.4) (lubridate?).\n\n\nCode\n# Get the latest snapshot file\nlatest_snapshot &lt;- get_latest_snapshot()\n# \n# You can then use these in your subsequent code:\ntemp_file &lt;- tempfile(fileext = \".xlsx\")\ndrive_download(\n  file = latest_snapshot$snapshot$id,\n  path = temp_file,\n  overwrite = TRUE\n)\n\n# Correction to reset back to excel origin\nDaysDiff &lt;- as.numeric(as.duration(interval(ymd(\"1899-12-30\"), ymd(\"1970-01-01\"))),\"days\")\n\nSnapshot &lt;- read_xlsx(\n  temp_file,\n  sheet = \"General\",\n  colNames = TRUE,\n  detectDates = FALSE\n  ) |&gt;\n  mutate(\n        # Convert to dates\n        across(\n            starts_with(\"Date\"),\n            ~lubridate::as_date(., origin = \"1899-12-30\")\n        ),\n        # Then get the numeric values directly\n        across(\n            starts_with(\"Date\"),\n            ~as.numeric(.)+ DaysDiff,\n            .names = \"{.col}Num\"\n        ),\n        Sex2 = case_when( # Fix up sex entries\n          Sex == \"M\" ~ \"Male\",\n          Sex == \"Male\" ~ \"Male\",\n          Sex == \"F\" ~ \"Female\",\n          Sex == \"Female\" ~ \"Female\",\n          Sex == \"N\" ~ NA_character_,\n          .default = NA_character_\n        ),\n        PatientID = stringr::str_split_i(TreatmentID,\"\\\\.\",1)\n    ) |&gt; left_join(\n    MasterPatient |&gt; dplyr::select(\n    PatientID,\n    AlternateID2,\n    AlternateID\n),\nby = \"PatientID\",\nrelationship = \"many-to-many\"\n) |&gt; tidyr::unite(\n  \"CombID\",\n  c(\"PatientID\",\"AffectedSide\"),\n  sep = \".\",\n  na.rm = FALSE,\n  remove = FALSE\n) |&gt; group_by(\n  CombID\n) |&gt; arrange(\n  DateInitialExaminationNum\n  ) |&gt; mutate(\n  RecordNum = row_number()\n) |&gt; ungroup() |&gt; \n    relocate(\n        c(PatientID, ends_with(\"Num\"),RecordNum),\n        .before = TreatmentID\n    ) \n\n\n#Import STROBEInput to conduct flowchart and record selection \"Strobe_Input\"\n\nSTROBEInput &lt;- read_xlsx(\n  temp_file,\n  sheet = \"Strobe_Input\",\n  colNames = TRUE,\n  detectDates = FALSE\n  )\n\n# Clean up\nunlink(temp_file)"
  },
  {
    "objectID": "SOFARI_Baseline.html#record-6-participants",
    "href": "SOFARI_Baseline.html#record-6-participants",
    "title": "Pain and function at baseline assessment of foot and ankle pathology: An analysis of the SOFARI Registry",
    "section": "3.4 RECORD [6] Participants",
    "text": "3.4 RECORD [6] Participants\n\nParticipants are eligible for inclusion in the SOFARI registry if they meet the following criteria\n\nPresented with a pathology localised to the foot or ankle\nOffered or recommended treatment by the reviewing surgeon (operative or non-operative)\nAged 16 or over at the time of initial consultation for the condition included in the registry\nHave not withdrawn their data from the registry (opt-out)\n\n\n3.4.1 Record [6.1] Sample selection\n\nRecord selection was based on the following criteria;\n\nThe status of the record was not set to Archived (the treatment record does not meet inclusion into the registry).\nThe status of the record was not set to Pending Initial Consultation or Pending Imaging (not eligible for formal diagnosis).\nThe record represented the first presentation for the limb within the registry. This may not represent the first presentation to the clinic.\nThe record was eligible for baseline PROMs capture. That is, sufficient time was available between patient registration and definitive treatment offered by the reviewing surgeon. In some cases, trauma cases first present to the clinic after their definitive surgical treatment and baseline PROMs cannot be captured prior to surgery.\nDiagnosis text had been retrieved at the time of analysis.\n\nThe consort package (v1.2.2) (consort?) was used to create a table of indications for exclusion for each record and plot a flowchart (see 13.1) indicating the flow from total records processed to the final inclusion sample for analysis.\n\n\nCode\n# EligibleAtPreop \n# - NFFU/failed with no treatment date\n# - NFFU/failed &lt; treatmentdate\n# - pre-registry treatment\n# - recordcreationdate &gt;= datetreatment\n# - registrystatus = open:no proms &lt;= datetreatment\n\n\nSTROBEFlow &lt;- STROBEInput |&gt; dplyr::filter(\n  !is.na(TreatmentID)\n) |&gt; left_join(\n  Snapshot |&gt; dplyr::select(\n    TreatmentID,\n    CombID,\n    DateInitialExamination,\n    EligibleAtPreop\n  ),\n  by = \"TreatmentID\"\n) |&gt; dplyr::select(\n  TreatmentID,\n  CombID,\n  TreatmentStatus,\n  TreatmentStatusNotes,\n  DateInitialExamination,\n  EligibleAtPreop,\n  DiagnosisRawPrelim,\n  DiagnosisRawFinal\n) |&gt; group_by(\n  CombID\n) |&gt; arrange(\n  DateInitialExamination\n  ) |&gt; mutate(\n  RecordNum = if_else(!is.na(CombID),row_number(),NA)\n) |&gt; ungroup() |&gt;\n  dplyr::mutate(\n  EligibleAtPreop = if_else(is.na(EligibleAtPreop),\"No\",EligibleAtPreop),\n  TreatmentStatusNotes2 = case_when(\n    stringr::str_detect(str_to_lower(TreatmentStatusNotes), \"acl|amput*|wrist|shoulder|knee|(non.*registry)|nfr|(pathology not)|(non.*ankle)|(not.*registry)\") ~ \"Non-Registry Pathology\",\n    stringr::str_detect(str_to_lower(TreatmentStatusNotes), \"error|(not failed)|reop*|duplicate|incorrect|mention|superfluous|left|right|side|(complication only)|(not needed)\") ~ \"Accessory Record\",\n        stringr::str_detect(str_to_lower(TreatmentStatusNotes), \"(sa.*patient)|(sa//ak)\") ~ \"Non-Registry Clinician\",\n    stringr::str_detect(str_to_lower(TreatmentStatusNotes), \"(did not)|canx|dna|cx|attend|appointment|appt|cancel|resch|(never.*(arrived|came|return*))\") ~ \"No Initial Consult\",\n    stringr::str_detect(str_to_lower(TreatmentStatusNotes), \"empty|(no.*(note|record))|information|insufficient|(cannot retrieve)|(enough.*info*)\") ~ \"No Patient File\",\n    stringr::str_detect(str_to_lower(TreatmentStatusNotes), \"pre-registry|existing|prior\") ~ \"Pre-Registry Treatment\",\n    stringr::str_detect(str_to_lower(TreatmentStatusNotes), \"intervention|elsewhere|(treated prior)|(no.*(treatment|pathology))|refer*|(no.*diagnosis)|(other.*surg*)|(surgeon.*other)|2nd|second|hesitant|(not.*viable)|(failed.*return)|public\") ~ \"No Treatment Offered\",\n    stringr::str_detect(str_to_lower(TreatmentStatusNotes), \"withdraw*|(opt*.*out)|(unable.*recruit*)\") ~ \"Patient Opt-Out\",\n    .default = TreatmentStatusNotes\n  ),\nexclusion1 = case_when( #exclusion before induction\n    stringr::str_detect(str_to_lower(TreatmentStatus), \"pending: ic\") ~ \"No Initial Consult\",\n    stringr::str_detect(str_to_lower(TreatmentStatus),\"treatment\") &\n    stringr::str_detect(str_to_lower(TreatmentStatusNotes),\"imaging\") ~ \"Pending Diagnosis\",\n    stringr::str_detect(str_to_lower(TreatmentStatus),\"archived\") ~ stringr::str_to_title(TreatmentStatusNotes2),\n    .default = NA_character_\n    ),\nexclusion2 = case_when( #exclusion after induction\n    is.na(exclusion1) & EligibleAtPreop == \"Yes\" & RecordNum == 1 ~ NA_character_,\n    is.na(exclusion1) & EligibleAtPreop == \"Yes\" & RecordNum &gt; 1 ~ \"Subsequent Presentation\",\n    is.na(exclusion1) & RecordNum == 1 & EligibleAtPreop == \"No\" ~ \"Not eligible for Baseline\"\n\n),\nexclusion3 = case_when(\n  is.na(exclusion1) & is.na(exclusion2) & is.na(DiagnosisRawFinal) & is.na(DiagnosisRawPrelim) ~ \"Missing Diagnosis\",\n  .default = NA_character_\n)\n)|&gt; dplyr::rename(\n  trialno = \"TreatmentID\"\n)\n\nAnalysisList = STROBEFlow |&gt; dplyr::filter(\n  is.na(exclusion1),\n  is.na(exclusion2),\n  is.na(exclusion3)\n)\n\n\nA masterfile was created with tidyverse syntax of all included records for further processing.\n\n\nCode\nMasterTable1 &lt;- Snapshot |&gt; dplyr::select(\n  EligibleAtPreop:VR12_Mental_TotalScore_Preop,\n  Satisfaction_Preop:PCSSF_TotalScore_Preop,\n  Sex2,\n  -Sex\n) |&gt; dplyr::filter( # Filter archived and pending: ic records\n  TreatmentID %in% AnalysisList$trialno\n) |&gt; mutate(\n  PreviousPath = case_when(\n    PreviousPathology_Preop == \"Both sides\" ~ \"Bilateral\",\n    str_detect(PreviousPathology_Preop,\"same side\") ~ \"Ipsilateral\",\n    str_detect(PreviousPathology_Preop,\"opposite side\") ~ \"Contralateral\",\n    .default = NA_character_\n  ),\n  PreviousSurgery = case_when(\n    PreviousSurgery_Preop == \"Both sides\" ~ \"Bilateral\",\n    str_detect(PreviousSurgery_Preop,\"same side\") ~ \"Ipsilateral\",\n    str_detect(PreviousSurgery_Preop,\"opposite side\") ~ \"Contralateral\",\n    .default = NA_character_\n  )\n) |&gt; dplyr::select(\n  -c(\n    PreviousPathology_Preop,\n    PreviousSurgery_Preop\n  )\n) \n\n\n\nA total of 12494 records were selected, with dates of initial examination ranging from 2019-07-19 to 2025-05-09.\n\n\n\n3.4.2 Record [6.2] Algorithm validation\n\n\n\n3.4.3 Record [6.3] Data linkage\n\nNo data linkage was performed for this analysis."
  },
  {
    "objectID": "SOFARI_Baseline.html#record-7-variables",
    "href": "SOFARI_Baseline.html#record-7-variables",
    "title": "Pain and function at baseline assessment of foot and ankle pathology: An analysis of the SOFARI Registry",
    "section": "3.5 RECORD [7] Variables",
    "text": "3.5 RECORD [7] Variables\n\nKey variables defined as part of this analysis are summarised below and retrieved from the core dataset of the SOFARI registry.\n\n\n\nTable 4: Summary of key variable definitions in the analysis\n\n\n\n\n\n\n\n\n\n\n\nCategory\nVariable\nDefinition - Comments\nCitation\n\n\n\n\nOutcomes\nPain catastrophising scale - Short form\n7-question short version of the PCS\nTotal score from sum of individual items\n(cheng2019?)\n\n\n\nVR12- MCS\n12-question general health questionnaire.\nProduces mental and physical sub-scores\n(Selim2009?)\n\n\n\nFAOS\n42-question with 5 subscales (Pain, ADL, Sport, Symptoms, Quality of Life)\n(Roos, Brandsson, and Karlsson 2001)\n\n\nExposures\nCohort (Region)\ncategorisation of pathology based on anatomical region\n\n\n\nConfounders\nAge\nage at the date of initial examination\n\n\n\n\nSex\nself-reported by the patient (male, female)\n\n\n\n\nComorbidity score\nSelf-assessed comorbidity score (SACQ) sum of 12 items rated 0 - 3\n(Sangha2003?)\n\n\n\n\n\n\nThe self-assessed comorbidity score had to added to the dataset by calculating from individual responses included in the registry snapshot. The scores were then added to the analysis master table.\n\n\nCode\n# Apply to your data\nSRCQScore &lt;- MasterTable1 |&gt; \n  dplyr::select(\n    TreatmentID,\n    starts_with(\"comorb\")\n  ) |&gt; \n  mutate(\n    across(starts_with(\"Comorb\"), \n           ~ case_when(\n             is.na(.) ~ NA,\n             . == \"I do not have the problem\" ~ 0,\n             . == \"I have the problem\" ~ 1,\n             . == \"I am receiving treatment for it\" | \n               . == \"I have the problem, I am receiving treatment for it\" ~ 2,\n             . == \"The problem limits my activities\" | \n               . == \"I have the problem, I am receiving treatment for it, The problem limits my activities\" ~ 3,\n             TRUE ~ NA_real_  # Add default case\n           )\n    )\n  ) |&gt; \n  mutate(\n    SRCQTotalScore = rowSums(across(where(is.numeric)))\n  )\n\n\n\n\nCode\nMasterTable2 &lt;- MasterTable1 |&gt; left_join(\n  SRCQScore |&gt; dplyr::select(\n    TreatmentID,\n    SRCQTotalScore\n  ),\n  by = \"TreatmentID\"\n) |&gt; dplyr::select(\n  !(starts_with(\"Comorb\"))\n)\n\n\nExtract individual PCS scores\n\n\nCode\nPCSTable  &lt;- MasterTable1 |&gt; \n  dplyr::select(\n    TreatmentID,\n    starts_with(\"PCSSF\")\n  ) |&gt; \n  dplyr::mutate(\n    across(starts_with(\"PCSSF\"),\n           ~as.numeric(stringr::str_extract(.,\"\\\\d+\"))\n    )\n  )\n\n\nAccording to (cheng2019?) the PCS-SF (and perhaps the full scale as well) would be best scored by simply adding all the items up. The present analysis may provide a platform for future examination of subscales of PCS such as Rumination, Magnification and Helplessness with respect to baseline pain.\nThe PCS-SF total score was added to the master table.\n\n\nCode\nMasterTable3 &lt;- MasterTable2 |&gt; dplyr::select(\n  !(starts_with(\"PCSSF\"))\n) |&gt; left_join(\n  PCSTable |&gt; dplyr::select(\n    TreatmentID,\n    PCSSF_TotalScore_Preop\n  ),\n  by = \"TreatmentID\"\n) |&gt; dplyr::select(\n  TreatmentID,\n  PatientID,\n  TreatmentType,\n  Sex2,\n  Provider,\n  AgeAtInitialExam,\n  InjuryToPresentation,\n  VR12_Physical_TotalScore_Preop,\n  VR12_Mental_TotalScore_Preop,\n  SRCQTotalScore,\n  PCSSF_TotalScore_Preop,\n  Satisfaction_Preop,\n  PreviousPath,\n  PreviousSurgery\n)\n\n\nExtract individual PCS scores\n\n\nCode\nFAOSTable  &lt;- Snapshot |&gt; dplyr::filter(\n  TreatmentID %in% MasterTable1$TreatmentID\n) |&gt; dplyr::select(\n    TreatmentID,\n    starts_with(\"FAOS\") & contains(\"TotalScore\") & contains(\"Preop\")\n  ) |&gt;\n  dplyr::mutate(\n    across(starts_with(\"FAOS\"),\n           ~as.numeric(stringr::str_extract(.,\"\\\\d+\"))\n    )\n  )\n\n\nAccording to (cheng2019?) the PCS-SF (and perhaps the full scale as well) would be best scored by simply adding all the items up. The present analysis may provide a platform for future examination of subscales of PCS such as Rumination, Magnification and Helplessness with respect to baseline pain.\nThe FAOS subscale total scores were added to the master table.\n\n\nCode\nMasterTable3 &lt;- MasterTable2 |&gt; left_join(\n  FAOSTable,\n  by = \"TreatmentID\"\n) |&gt; dplyr::select(\n  TreatmentID,\n  PatientID,\n  TreatmentType,\n  Sex2,\n  Provider,\n  AgeAtInitialExam,\n  InjuryToPresentation,\n  VR12_Physical_TotalScore_Preop,\n  VR12_Mental_TotalScore_Preop,\n  SRCQTotalScore,\n  PCSSF_TotalScore_Preop,\n  Satisfaction_Preop,\n  PreviousPath,\n  PreviousSurgery,\n  starts_with(\"FAOS\")\n)\n\n\n\n3.5.1 Diagnosis\nRaw text stored in the registry snapshot was processed with custom functions (see Functions for Processing). Additional processing was performed to create a Region label, describing the anatomical region in which the pathology affected.\n\n\nCode\n# Group by sequence\n\nDiagSequence &lt;- DiagTerm |&gt; tidyr::unite(\n  \"SequenceID1\",\n  c(TreatmentID,\n    SequenceID\n    ),\n  na.rm = TRUE, \n  remove = FALSE, \n  sep = \".\"\n  ) |&gt; group_by(\n    SequenceID1\n    ) |&gt; summarize(\n    Term2 = str_c(Term1, collapse = \" \")\n  ) |&gt; ungroup() |&gt; mutate(\n    TreatmentID = stringr::str_remove(SequenceID1, \"\\\\.[^.]*$\")\n  )\n\n# Group by Treatment\n\nDiagTreatment &lt;- DiagSequence |&gt; group_by(\n  TreatmentID\n) |&gt; summarise(\n  Term3 = str_c(\n    Term2,\n    collapse = \"; \"\n  )\n) |&gt; ungroup()\n\n\n\n\nCode\nDiagFunc2 &lt;- DiagFunc1 |&gt; \n  mutate(\n    RowCount1 = n(),\n    .by = TreatmentID\n  ) |&gt; \n  dplyr::select(\n    -(Ankle:NegatePathology)\n  ) |&gt; \n  mutate(\n    SequenceCat1 = if_else(\n      has_region &gt;= 1 & has_pathology &gt;= 1,\n      \"Classified\",\n      \"No\"\n    )\n  ) |&gt; \n  group_by(TreatmentID) |&gt; \n  arrange(desc(SequenceRow), .by_group = TRUE) |&gt; \n  mutate(\n    Product = has_region * has_pathology,\n    SequenceCatLead = lead(SequenceCat1),\n    ResetFlag = case_when( \n      lag(Product) &gt;= 1 & Product == 0 ~ 1,\n      lag(Product) &lt; 1 & Product &lt; 1 ~ 1,\n      Product &gt;= 1 & lag(Product) &lt; 1 ~ 1,\n      SequenceRow == max(SequenceRow) & Product == 0 ~ 1,\n      SequenceRow == max(SequenceRow) & Product &gt;= 1 ~ 0,\n      .default = 0\n    )\n  ) |&gt; \n  ungroup()\n\n\n\n\nCode\nDiagFunc2a &lt;- DiagFunc2 |&gt; filter(\n  Product &gt; 0,\n  ResetFlag == 0\n)\n\n\nDiagFunc2b &lt;- left_join(\n  DiagFunc2 |&gt; filter(\n    ResetFlag == 1\n  ) |&gt; distinct(\n    TreatmentID,\n    .keep_all = TRUE\n  ),\nDiagFunc2c &lt;- DiagFunc2 |&gt; filter(\n  ResetFlag == 1\n) |&gt; group_by(\n  TreatmentID\n) |&gt; summarise( # COLLAPSE rows into 1. JOIN back into FuncX (bindrows)\n   Term3 = str_c(\n     Term2,\n     collapse = \"; \"\n   )\n ),\nby = \"TreatmentID\"\n) |&gt; ungroup() |&gt; dplyr::select(\n  -Term2\n) |&gt; rename(\n  Term2 = \"Term3\"\n)\n\n\nDiagFunc3 &lt;- bind_rows(\n  DiagFunc2a,\n  DiagFunc2b\n) |&gt; arrange(\n  TreatmentID\n) |&gt; dplyr::select(\n  -(has_region:ResetFlag)\n)\n\n\n\n\nCode\nDiagRegion &lt;- DiagFunc4 |&gt; dplyr::select(\n  Term2,\n  SequenceIDUpdate,\n  TreatmentID:Foot\n) |&gt; dplyr:: select(\n  -SequenceRow\n) |&gt; tidyr::pivot_longer(\n  cols = !c(TreatmentID,SequenceIDUpdate,Term2),\n  names_to = \"Region\",\n  values_to = \"RegionPresence\"\n) |&gt; dplyr::filter(\n  RegionPresence &gt; 0,\n  !is.na(Region)\n) |&gt; dplyr::mutate(\n  RegionCount = n_distinct(Region),\n  RegionCat = if_else(RegionCount &gt; 1,\"Multiple\",\"Isolated\"),\n  .by = TreatmentID\n) |&gt; dplyr::select(\n  -RegionPresence\n)\n\n\n\n\nCode\nDiagPathology &lt;- DiagFunc4 |&gt; dplyr::select(\n  Term2,\n  TreatmentID,\n  SequenceIDUpdate,\n  Arthritis:Other\n) |&gt; tidyr::pivot_longer(\n  cols = !c(TreatmentID,SequenceIDUpdate,Term2),\n  names_to = \"Pathology\",\n  values_to = \"PathPresence\"\n) |&gt; filter(\n  PathPresence &gt; 0,\n  !is.na(Pathology)\n) |&gt; mutate(\n  PathCount = n_distinct(Pathology),\n  PathCat = if_else(PathCount &gt; 1,\"Multiple\",\"Isolated\"),\n  .by = TreatmentID\n)\n\n\n\n\nCode\nDiagRegion1 &lt;- DiagRegion |&gt; distinct(\n  TreatmentID,\n  .keep_all = TRUE\n) \n\n\nDiagPath1 &lt;- DiagPathology |&gt; distinct(\n  TreatmentID,\n  .keep_all = TRUE\n) \n\n\n\n\n3.5.2 Cohort\nA cohort label (combining pathology and region) was created from the processed diagnosis text.\n\n\nCode\n# Slice Down Snapshot based on diagnosis availability\n\nMasterTable4 &lt;- MasterTable3 |&gt; left_join(\n  DiagFunc4 |&gt; dplyr::select(\n    TreatmentID,\n    Term2\n  )  |&gt;\n  summarize(\n    Term3 = str_c(Term2, collapse = \" \"),\n    .by = TreatmentID\n  ),\n  by = \"TreatmentID\"\n)  |&gt; left_join(\n  DiagRegion1 |&gt; dplyr::select(\n    TreatmentID,\n    RegionCat\n  ),\n  by = \"TreatmentID\"\n) |&gt; left_join(\n  DiagPath1 |&gt; dplyr::select(\n    TreatmentID,\n    PathCat\n  ),\n  by = \"TreatmentID\"\n) |&gt; tidyr::unite(\n  \"Cohort\",\n  c(RegionCat,PathCat),\n  sep = \"_\",\n  na.rm = FALSE,\n  remove = FALSE\n) |&gt; left_join(\n  DiagRegion1 |&gt; filter(\n    RegionCat == \"Isolated\"\n    ) |&gt; dplyr::select(\n    TreatmentID,\n    Region\n  ),\n  by = \"TreatmentID\"\n) |&gt; left_join(\n  DiagPath1 |&gt; filter(\n    PathCat == \"Isolated\"\n    ) |&gt; dplyr::select(\n    TreatmentID,\n    Pathology\n  ),\n  by = \"TreatmentID\"\n) |&gt; mutate(\n  Cohort1 = case_when(\n    is.na(RegionCat) & is.na(PathCat) ~ NA_character_,\n    RegionCat == \"Multiple\" & PathCat == \"Multiple\" ~ \"Multiple\",\n    !is.na(Region) & is.na(Pathology) ~ Region,\n    is.na(Region) & !is.na(Pathology) ~ Pathology,\n    !is.na(Region) & !is.na(Pathology) ~ stringr::str_c(Region,Pathology, sep = \"_\")\n  )\n) |&gt; mutate(\n  Cohort2 = ifelse(n() &lt; 30, \"General\", Cohort1),\n  .by = Cohort1,\n  Region2 = if_else(\n    is.na(Region) & RegionCat == \"Multiple\", \"Multiple\", Region\n  )\n) |&gt; dplyr::select(\n  !c(\n    Region,\n    RegionCat\n  )\n) |&gt; dplyr::rename(\n  Region = \"Region2\"\n) \n\n\nEstablishing the breakdown of the sample by cohorts revealed that multiple pathologies across multiple regions of the foot-ankle was the most common presentation, followed by ankle_injury and multiple pathologies affecting the ankle (Figure 1).\n\n\nCode\nmin_count &lt;- 10\n\n# Basic counts\n  basic_counts1 &lt;- MasterTable4 |&gt;\n    count(Cohort2, sort = TRUE) %&gt;%\n    mutate(\n      percentage = n / sum(n) * 100,\n      cumulative_percentage = cumsum(percentage)\n    )\n\n\n # Create visualization\n  plot_data &lt;- basic_counts1 |&gt;\n    filter(\n      n &gt;= min_count,\n      !is.na(Cohort2)\n      )  # Filter for readability\n  \n  cohort_plot &lt;- ggplot(plot_data, aes(x = reorder(Cohort2, -n), y = n)) +\n    geom_bar(stat = \"identity\", fill = \"steelblue\") +\n    geom_text(aes(label = sprintf(\"%.1f%%\", percentage)), \n              vjust = -0.5, size = 3) +\n    theme_minimal() +\n    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n    labs(title = \"Distribution of Clinical Cohorts\",\n         x = \"Cohort\",\n         y = \"Count\")\n  \n  knitr::knit_print(cohort_plot)\n\n\n\n\n\n\n\n\nFigure 1: Breakdown of sample by defined cohorts - combined pathology and region labels.\n\n\n\n\n\n\n\n3.5.3 Bilateral Status\nThe bilateral status of each record in the registry snapshot was calculated by grouping by PatientID, establishing those records with &gt;1 record in the table, then calculating whether the bilateral record was;\n\nSimultaneous - where both records are presented and created at the same time\nIndex - the first limb to present for that patient within the registry\nSubsequent - the second (contralateral) limb to present for that patient within the registry that is separated from the first record by time.\nUnilateral - the record appears in the dataset with no record present for the contralateral limb\n\n\n\nCode\nSnapshotBilat1 &lt;- MasterTable4 |&gt; group_by(\n  PatientID\n) |&gt; summarise(\n  TreatmentCount = n()\n) |&gt; filter(\n  TreatmentCount &gt; 1\n)\n\nSnapshotBilat2 &lt;- Snapshot |&gt; filter(\n  PatientID %in% SnapshotBilat1$PatientID\n)\n\nSnapshotLeft1 &lt;- SnapshotBilat2 |&gt; filter(\n  AffectedSide == \"Left\"\n) |&gt; group_by(\n  PatientID\n) |&gt; arrange(\n  DateInitialExamination,\n  .by_group = TRUE\n) |&gt; dplyr::select(\n  TreatmentID,\n  CombID,\n  PatientID,\n  AffectedSide,\n  DateInitialExamination,\n  DateInitialExaminationNum,\n  TreatmentStatus,\n  TreatmentStatusNotes,\n  DateStatusChange\n) |&gt; slice_head(\n  n = 1\n) |&gt; ungroup()\n\nSnapshotRight &lt;- SnapshotBilat2 |&gt; filter(\n  AffectedSide == \"Right\"\n) |&gt; rename(\n  DIERight = \"DateInitialExamination\"\n) |&gt; group_by(\n  PatientID\n) |&gt; arrange(\n  DIERight,\n  .by_group = TRUE\n) |&gt; dplyr::select(\n  TreatmentID,\n  CombID,\n  PatientID,\n  AffectedSide,\n  DIERight,\n  TreatmentStatus,\n  TreatmentStatusNotes,\n  DateStatusChange\n) |&gt; slice_head(\n  n = 1\n) |&gt; ungroup() |&gt; left_join(\n  SnapshotLeft1 |&gt; dplyr::select(\n    PatientID,\n    DateInitialExamination\n  ),\n  by = \"PatientID\"\n  ) |&gt; rename(\n  DIELeft = \"DateInitialExamination\"\n) |&gt; mutate(\n   DIEDiff = as.numeric(as.duration(DIERight %--% DIELeft),\"weeks\")\n  ) |&gt; mutate(\n    BilateralPres = case_when(\n      DIEDiff == 0 ~ \"Simultaneous\",\n      DIEDiff &gt; 0 ~ \"Index\",\n      DIEDiff &lt; 0 ~ \"Subsequent\",\n      .default = \"Unilateral\"\n    )\n  )\n\nSnapshotLeft2 &lt;- SnapshotLeft1 |&gt; rename(\n  DIELeft = \"DateInitialExamination\"\n) |&gt; left_join(\n  SnapshotRight |&gt; dplyr::select(\n    PatientID,\n    DIERight\n  ),\n  by = \"PatientID\"\n  ) |&gt; mutate(\n   DIEDiff = as.numeric(as.duration(DIELeft %--% DIERight),\"weeks\")\n  ) |&gt; mutate(\n    BilateralPres = case_when(\n      DIEDiff == 0 ~ \"Simultaneous\",\n      DIEDiff &gt; 0 ~ \"Index\",\n      DIEDiff &lt; 0 ~ \"Subsequent\",\n      .default = \"Unilateral\"\n    )\n  ) |&gt; filter(\n    BilateralPres != \"Unilateral\"\n  )\n\n\nMarry back into the master table.\n\n\nCode\nMasterTable5 &lt;- left_join(\n  MasterTable4,\n  SnapshotLeft2 |&gt; dplyr::select(\n    TreatmentID,\n    BilateralPres\n  ) |&gt; rename(\n    BilateralPresLeft = \"BilateralPres\"),\n  by = \"TreatmentID\"\n) |&gt; left_join(\n  SnapshotRight |&gt; dplyr::select(\n    TreatmentID,\n    BilateralPres\n  ) |&gt; rename(\n    BilateralPresRight = \"BilateralPres\"),\n  by = \"TreatmentID\"\n) |&gt; tidyr::unite(\n  \"BilateralPres\",\n  c(BilateralPresLeft,BilateralPresRight),\n  na.rm = TRUE,\n  remove = TRUE\n) |&gt; mutate(\n  BilateralPres1 = if_else(\n    str_count(BilateralPres) &lt; 1,\n    \"Unilateral\",\n    BilateralPres\n  )\n) |&gt; dplyr::select(\n  -BilateralPres\n) |&gt; rename(\n  BilateralPres = \"BilateralPres1\"\n) |&gt; mutate(\n  BilateralDiag = stringr::str_detect(\n    Term3,\n    \"bilateral\"\n  )\n  )\n\n\n\n\n3.5.4 RECORD [7.1] Codes and Algorithms"
  },
  {
    "objectID": "SOFARI_Baseline.html#record-9-bias",
    "href": "SOFARI_Baseline.html#record-9-bias",
    "title": "Pain and function at baseline assessment of foot and ankle pathology: An analysis of the SOFARI Registry",
    "section": "3.6 RECORD [9] Bias",
    "text": "3.6 RECORD [9] Bias\n\nFor a discussion of biases in the context of the clinical registry utilised for this analysis, refer to (scholes2023?). Specific to this analysis, the following considerations are noted below.\n\n\n\nTable 5: Biases in an analysis of an observational cohort retrieved from a clinical registry\n\n\n\n\n\n\n\n\n\n\n\nBias\nDefinition\nSource\nMitigation\n\n\n\n\nSelection\n\n\n\n\n\nMisclassification\nTreatment record labelled into incorrect cohort. PROMs package not aligned to\n(Benchimol2015?)\nClinical text retrieved by two experienced reviewers and transferred to registry.\nCode functions used to process text in a repeatable workflow.\n\n\nImmortal Time\nIndividuals meet eligibility criteria that can only assessed after followup has started\n(nguyen2021?)\nPatients are enrolled at first presentation to the registry for their condition - but this does not necessarily represent first presentation to the clinic.\n\n\nMissing Data\nThe absence of a data value where a treatment record is eligible to have a data value collected\n(carroll2020?)\nMultiple imputation was used to impute missing values and model-based predictions of outcomes used\n\n\nPrevalent User\nFollow-up starts after eligible individuals have started the treatment. The follow-up time is left-truncated\n(nguyen2021?)\nEligibility and enrollment is performed prior to treatment offering for any patient or new presentation. Records where definitive treatment occurred before registry enrolment were excluded.\n\n\nPseudoreplication\nAnalyse data while ignoring dependency between observations. Inadequate model specification.\n(davies2015?; lazic2010?)\nBecause not all patients had multiple treatments, mixed effects models were poorly specified. A generalised linear model was utilised instead.\n\n\nConfounder\nAn variable of interest and a target outcome simultaneously influenced by a third variable\n(tennant2020?)\nPCS-SF models incorporated adjustment for confounders"
  },
  {
    "objectID": "SOFARI_Baseline.html#record-10-study-size",
    "href": "SOFARI_Baseline.html#record-10-study-size",
    "title": "Pain and function at baseline assessment of foot and ankle pathology: An analysis of the SOFARI Registry",
    "section": "3.7 RECORD [10] Study size",
    "text": "3.7 RECORD [10] Study size\n\nSample size was derived based on the available records from the Registry at the time of analysis."
  },
  {
    "objectID": "SOFARI_Baseline.html#record-11-quantitative-variables",
    "href": "SOFARI_Baseline.html#record-11-quantitative-variables",
    "title": "Pain and function at baseline assessment of foot and ankle pathology: An analysis of the SOFARI Registry",
    "section": "3.8 RECORD [11] Quantitative variables",
    "text": "3.8 RECORD [11] Quantitative variables\n\nNo categorisation of quantitative variables was undertaken in this analysis."
  },
  {
    "objectID": "SOFARI_Baseline.html#record-12-statistical-methods",
    "href": "SOFARI_Baseline.html#record-12-statistical-methods",
    "title": "Pain and function at baseline assessment of foot and ankle pathology: An analysis of the SOFARI Registry",
    "section": "3.9 RECORD [12] Statistical methods",
    "text": "3.9 RECORD [12] Statistical methods\n\n\n3.9.1 RECORD [12.1] Data access\n\nThe registry system represents all cases presenting to the rooms of collaborating specialists within Sydney, Australia from the inception of the clinical registry to the analysis date. All reviewed charts from the operating surgeons practice records (electronic medical record) were entered into database and the present analysis draws data from a regular compilation of the registry records (snapshot) produced quarterly by the registry administration team.\n\n\n3.9.2 RECORD [12.2] Data Cleaning\n\nText data was cleaned using custom functions as described in Functions for processing.\n\n3.9.2.1 Missingness\nIn the record selection workflow, patients with text in the diagnosis text field were included in the final analysis number. However, there was a proportion of patients that had text that could not be categorised into an anatomical region. For the purposes of this draft analysis, these cases will be removed and a round of chart review will be performed to resolve the discrepancy between the text and the classification code.\n\n\nCode\nMasterAnalysis &lt;- MasterTable5 |&gt; dplyr::select(\n  TreatmentID:Satisfaction_Preop,\n  Region,\n  BilateralPres,\n  starts_with(\"FAOS\")\n) |&gt; dplyr::filter(\n  !is.na(Region)\n) \n\n\nMissingness was visualised with the naniar package (v1.1.0) (naniar?). It showed that patients with a diagnosis also had other missing data, predominantly PROMs data.\n\n\nCode\nvis_miss(MasterAnalysis)\n\n\n\n\n\n\n\n\nFigure 2: Patterns of missingness across analysis variables\n\n\n\n\n\nThe mice (v3.18.0) (mice?) was used to impute the dataset. A predictor matrix was created to remove record identifiers and passive variables (e.g. PCS categorisation) from the imputation. Imputation was performed over 20 replications and stored in a variable for further processing.\n\n\nCode\n# First create your predictor matrix as before\npredM &lt;- mice::make.predictorMatrix(MasterAnalysis)\n\n# Switch off IDs from predicting\npredM[,\"TreatmentID\"] &lt;- 0 \npredM[\"TreatmentID\",] &lt;- 0\npredM[,\"PatientID\"] &lt;- 0 \npredM[\"PatientID\",] &lt;- 0\n\n# Create a method vector\nmeth &lt;- mice::make.method(MasterAnalysis)\n\n# Modified mice command including method specification\nMasterImp &lt;- mice::mice(\n  MasterAnalysis,\n  maxit = 10,\n  seed = 4218,\n  m = 20,\n  printFlag = FALSE,\n  predictorMatrix = predM,\n  method = meth\n  )\n\n\nA strip plot (Figure 3) were used to visually inspect the convergence of the imputation iterations against the original dataset.\n\n\nCode\nMasterImpStrip &lt;- mice::densityplot(MasterImp)\n\nknitr::knit_print(MasterImpStrip)\n\n\n\n\n\n\n\n\nFigure 3: Strip plot of imputed data over 5 iterations with 20 imputations per iteration.\n\n\n\n\n\nThe estimated FAOS-Pain subscore from the imputation model versus the distribution of the observed data was plotted as a visual inspection of the imputation result.\n\n\nCode\nFAOSPainImp &lt;- ggplot() +\n  geom_density(data = complete(MasterImp, 1), aes(x = FAOS_Pain_TotalScore_Preop, color = \"Observed\")) +\n  geom_density(data = complete(MasterImp, 2:10), aes(x = FAOS_Pain_TotalScore_Preop, color = \"Imputed\"))\n\nknitr::knit_print(FAOSPainImp)\n\n\n\n\n\n\n\n\nFigure 4: Estimated versus observed FAOS-Pain for the analysis cohort.\n\n\n\n\n\n\n\n\n3.9.3 RECORD [12.3] Linkage\n\nNo data linkage was performed for this analysis.\n\n\n3.9.4 Analysis Methods\nParticipant flow - consort package and flow chart Descriptive - gtsummary and prepared for display with knitr Outcome data - ggplot2 complete case analysis\nA flow chart was created with the consort package (v1.2.2) (consort?) to describe the inclusion and exclusion of records into the sample pool for the present analysis to be drawn from. Patient demographics and pathology characteristics were summarised using gtsummary (v2.3.0) (gtsummary?). Graphs were generated using ggplot2 (v3.5.2) (ggplot2?). Graphs and tables were prepared for display using knitr (v1.50) (knitr?). A linear model was fitted to the imputed data using stats (v4.4.2) (stats?) with the following form.\n\n\nCode\n#Pain\n\nFAOSPainMod1 &lt;- with(\n  MasterImp, \n  exp = lm(\n    FAOS_Pain_TotalScore_Preop ~ Region\n    )\n)\n\nFAOSPainMod2 &lt;- with(\n  MasterImp, \n  exp = lm(\n    FAOS_Pain_TotalScore_Preop ~ Region + AgeAtInitialExam + Sex2 + BilateralPres + SRCQTotalScore + VR12_Mental_TotalScore_Preop + PCSSF_TotalScore_Preop\n    )\n)\n\n\n#Symptoms\n\nFAOSSympMod1 &lt;- with(\n  MasterImp, \n  exp = lm(\n    FAOS_Symptom_TotalScore_Preop ~ Region\n    )\n)\n\nFAOSSympMod2 &lt;- with(\n  MasterImp, \n  exp = lm(\n    FAOS_Symptom_TotalScore_Preop ~ Region + AgeAtInitialExam + Sex2 + BilateralPres + SRCQTotalScore + VR12_Mental_TotalScore_Preop\n    )\n)\n\n#ADL\n\nFAOSADLMod1 &lt;- with(\n  MasterImp, \n  exp = lm(\n    FAOS_DailyLiving_TotalScore_Preop ~ Region\n    )\n)\n\nFAOSADLMod2 &lt;- with(\n  MasterImp, \n  exp = lm(\n    FAOS_DailyLiving_TotalScore_Preop ~ Region + AgeAtInitialExam + Sex2 + BilateralPres + SRCQTotalScore + VR12_Physical_TotalScore_Preop + VR12_Mental_TotalScore_Preop\n    )\n)\n\n#Sport\n\nFAOSSportMod1 &lt;- with(\n  MasterImp, \n  exp = lm(\n    FAOS_Sport_TotalScore_Preop ~ Region\n    )\n)\n\nFAOSSportMod2 &lt;- with(\n  MasterImp, \n  exp = lm(\n    FAOS_Sport_TotalScore_Preop ~ Region + AgeAtInitialExam + Sex2 + BilateralPres + SRCQTotalScore + VR12_Physical_TotalScore_Preop + VR12_Mental_TotalScore_Preop\n    )\n)\n\n#QoL\n\nFAOSQOLMod1 &lt;- with(\n  MasterImp, \n  exp = lm(\n    FAOS_Quality_TotalScore_Preop ~ Region\n    )\n)\n\nFAOSQOLMod2 &lt;- with(\n  MasterImp, \n  exp = lm(\n    FAOS_Quality_TotalScore_Preop ~ Region + AgeAtInitialExam + Sex2 + BilateralPres + SRCQTotalScore + VR12_Physical_TotalScore_Preop + VR12_Mental_TotalScore_Preop\n    )\n)\n\n\nThe model was summarised using gtsummary. Predicted values for all model variables were generated from the model object using marginaleffects (v0.28.0) (marginaleffects?)."
  },
  {
    "objectID": "SOFARI_Baseline.html#record-13-participants",
    "href": "SOFARI_Baseline.html#record-13-participants",
    "title": "Pain and function at baseline assessment of foot and ankle pathology: An analysis of the SOFARI Registry",
    "section": "4.1 RECORD [13] Participants",
    "text": "4.1 RECORD [13] Participants\n\n\nThe initial export from the registry returned 21635 records of all types.\n\n\n4.1.1 RECORD [13.1] Participant Flow\n\nThe diagram below (Figure 5) summarises recruitment and categorisation of patients from the SOFARI registry into the final analysis cohort.\n\n\nCode\nSTROBEplot &lt;- consort_plot(\n  data = STROBEFlow,\n  orders = c(\n    trialno = \"Population\",\n    exclusion1 = \"Screened Out\",\n    trialno = \"Active Records\",\n    exclusion2 = \"Excluded\",\n    trialno = \"Total Pool\",\n    exclusion3 = \"Not Available\",\n    trialno = \"Available Pool\"\n  ),\n  side_box = c(\n    \"exclusion1\",\n    \"exclusion2\",\n    \"exclusion3\"\n  ),\n  cex = 0.8\n)\n\nknitr::knit_print(STROBEplot)\n\n\n\n\n\n\n\n\nFigure 5: Flow chart of treatment record inclusion for analysis."
  },
  {
    "objectID": "SOFARI_Baseline.html#record-14-patient-characteristics",
    "href": "SOFARI_Baseline.html#record-14-patient-characteristics",
    "title": "Pain and function at baseline assessment of foot and ankle pathology: An analysis of the SOFARI Registry",
    "section": "4.2 RECORD [14] Patient Characteristics",
    "text": "4.2 RECORD [14] Patient Characteristics\n\nSummarising the sample by anatomical region showed the ankle to be most common presentation, followed by multiple regions (Figure 6).\n\n\nCode\nmin_count &lt;- 10\n\n# Basic counts\n  basic_counts2 &lt;- MasterAnalysis |&gt; \n    count(Region, sort = TRUE) %&gt;%\n    mutate(\n      percentage = n / sum(n) * 100,\n      cumulative_percentage = cumsum(percentage)\n    )\n\n\n # Create visualization\n  plot_data &lt;- basic_counts2 |&gt;\n    filter(\n      n &gt;= min_count,\n      !is.na(Region)\n      )  # Filter for readability\n  \n  cohort_plot &lt;- ggplot(plot_data, aes(x = reorder(Region, -n), y = n)) +\n    geom_bar(stat = \"identity\", fill = \"steelblue\") +\n    geom_text(aes(label = sprintf(\"%.1f%%\", percentage)), \n              vjust = -0.5, size = 3) +\n    theme_minimal() +\n    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n    labs(title = \"Distribution of Diagnostic Groups\",\n         x = \"Region\",\n         y = \"Count\")\n  \n  knitr::knit_print(cohort_plot)\n\n\n\n\n\n\n\n\nFigure 6: Breakdown of sample by diagnostic group - region labels.\n\n\n\n\n\nPatient characteristics for the sample are summarised in Table 2.\n\n\nCode\nTable4 &lt;- gtsummary::tbl_summary(\n  MasterAnalysis |&gt; dplyr::select(\n    !(c(\n      TreatmentID,\n      PatientID,\n      PCSSF_TotalScore_Preop\n    ))\n  ),\nlabel = list(\n    AgeAtInitialExam ~ \"Age\",\n    InjuryToPresentation ~ \"Onset to Presentation (Days)\",\n    #BMI ~ \"Body Mass Index\",\n    BilateralPres ~ \"Bilateral\",\n    Region ~ \"Diagnostic Group\",\n    Sex2 ~ \"Female\",\n    Satisfaction_Preop ~ \"Symptom Satisfaction\"\n    ),\n    type = list(\n    Sex2 ~ \"dichotomous\"\n    ),\n    value = list(\n      Sex2 ~ \"Female\"\n    ),\n    statistic = list(\n      all_continuous() ~ \"{mean} ({sd})\",\n      all_categorical() ~ \"{p}% ({n})\"\n      ),\n    missing = \"no\"\n) |&gt; gtsummary::add_n() |&gt; gtsummary::add_ci(statistic = list(all_categorical() ~ \"{conf.low} - {conf.high}\",\n                          all_continuous() ~ \"{conf.low} - {conf.high}\")) |&gt; gtsummary::add_stat_label(\n    location = \"row\"\n  ) \n    # |&gt; modify_table_styling(\n    #   columns = label,\n    #   rows = label == \"DVA\",\n    #   footnote = \"DVA = Department of Veterans Affairs\"\n    # ) %&gt;% modify_table_styling(\n    #   columns = label,\n    #   rows = label == \"TAC\",\n    #   footnote = \"TAC = Transport Accident Commission\"\n    # )\n\nknitr::knit_print(Table4)\n\n\n\n\nTable 6: Summary of patient and treatment record characteristics for the analysed sample.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN\nN = 11,921\n95% CI\n\n\n\n\nTreatmentType, % (n)\n11,919\n\n\n\n\n\n\n    Primary\n\n\n97% (11,595)\n97 - 98\n\n\n    Revision Else\n\n\n1.9% (232)\n1.7 - 2.2\n\n\n    Revision Own\n\n\n0.8% (92)\n0.63 - 0.95\n\n\nFemale, % (n)\n11,895\n56% (6,653)\n55 - 57\n\n\nProvider, % (n)\n11,921\n\n\n\n\n\n\n    AW\n\n\n63% (7,537)\n62 - 64\n\n\n    MS1\n\n\n7.6% (902)\n7.1 - 8.1\n\n\n    MS2\n\n\n22% (2,578)\n21 - 22\n\n\n    RM\n\n\n7.6% (904)\n7.1 - 8.1\n\n\nAge, Mean (SD)\n11,842\n50 (18)\n49 - 50\n\n\nOnset to Presentation (Days), Mean (SD)\n6,222\n276 (516)\n263 - 289\n\n\nVR12_Physical_TotalScore_Preop, Mean (SD)\n6,605\n38 (11)\n38 - 38\n\n\nVR12_Mental_TotalScore_Preop, Mean (SD)\n6,598\n51 (11)\n51 - 52\n\n\nSRCQTotalScore, Mean (SD)\n5,849\n2.63 (2.93)\n2.6 - 2.7\n\n\nSymptom Satisfaction, % (n)\n6,353\n\n\n\n\n\n\n    Neutral\n\n\n6.4% (409)\n5.9 - 7.1\n\n\n    Somewhat dissatisfied\n\n\n30% (1,920)\n29 - 31\n\n\n    Somewhat satisfied\n\n\n2.8% (175)\n2.4 - 3.2\n\n\n    Very dissatisfied\n\n\n59% (3,780)\n58 - 61\n\n\n    Very satisfied\n\n\n1.1% (69)\n0.85 - 1.4\n\n\nDiagnostic Group, % (n)\n11,921\n\n\n\n\n\n\n    Ankle\n\n\n34% (4,040)\n33 - 35\n\n\n    Foot\n\n\n1.0% (124)\n0.87 - 1.2\n\n\n    Forefoot\n\n\n25% (2,952)\n24 - 26\n\n\n    Midfoot\n\n\n9.6% (1,146)\n9.1 - 10\n\n\n    Multiple\n\n\n25% (3,014)\n25 - 26\n\n\n    Rearfoot\n\n\n5.4% (645)\n5.0 - 5.8\n\n\nBilateral, % (n)\n11,921\n\n\n\n\n\n\n    Index\n\n\n0.6% (68)\n0.45 - 0.73\n\n\n    Simultaneous\n\n\n13% (1,564)\n13 - 14\n\n\n    Subsequent\n\n\n0.6% (69)\n0.45 - 0.74\n\n\n    Unilateral\n\n\n86% (10,220)\n85 - 86\n\n\nFAOS_Symptom_TotalScore_Preop, Mean (SD)\n6,218\n65 (23)\n64 - 65\n\n\nFAOS_Pain_TotalScore_Preop, Mean (SD)\n6,215\n60 (22)\n60 - 61\n\n\nFAOS_DailyLiving_TotalScore_Preop, Mean (SD)\n6,211\n69 (24)\n69 - 70\n\n\nFAOS_Sport_TotalScore_Preop, Mean (SD)\n6,172\n49 (32)\n48 - 49\n\n\nFAOS_Quality_TotalScore_Preop, Mean (SD)\n6,209\n37 (25)\n37 - 38\n\n\n\nAbbreviation: CI = Confidence Interval"
  },
  {
    "objectID": "SOFARI_Baseline.html#record-15-outcome-data",
    "href": "SOFARI_Baseline.html#record-15-outcome-data",
    "title": "Pain and function at baseline assessment of foot and ankle pathology: An analysis of the SOFARI Registry",
    "section": "4.3 RECORD [15] Outcome data",
    "text": "4.3 RECORD [15] Outcome data\n\nComplete case analysis displayed unique distributions of PCS-SF total score between diagnostic groups (Figure 7).\n\n\nCode\nFAOSPlot1 &lt;- ggplot(data = MasterAnalysis, mapping = aes(y = FAOS_Pain_TotalScore_Preop, x = Region)) + stat_slabinterval(aes(thickness = after_stat(pdf*n)), scale = 0.7, fill = \"steelblue\") +\n  stat_dotsinterval(side = \"right\", scale = 0.7, slab_linewidth = NA, fill = \"steelblue\") + labs(y = \"FAOS Pain\")\n\n\nFAOSPlot2 &lt;- ggplot(data = MasterAnalysis |&gt; dplyr::filter(!is.na(Sex2)), mapping = aes(y = FAOS_Pain_TotalScore_Preop, x = Sex2)) + stat_slabinterval(aes(thickness = after_stat(pdf*n)), scale = 0.7, fill = \"steelblue\") +\n  stat_dotsinterval(side = \"right\", scale = 0.7, slab_linewidth = NA, fill = \"steelblue\") + labs(y = \"FAOS Pain\")\n\n\n# Plot 3: Age relationship - this needs the most careful handling of missing data\n# First, create a dataset with complete cases for the model\ncomplete_data &lt;- MasterAnalysis |&gt; \n  dplyr::filter(!is.na(FAOS_Pain_TotalScore_Preop) & !is.na(AgeAtInitialExam))\n\n# Check if we have enough data\nif(nrow(complete_data) &lt; 10) {\n  warning(\"Very few complete cases available for regression analysis\")\n}\n\n# Fit the linear model on complete data only\nFAOSlm_simple &lt;- lm(FAOS_Pain_TotalScore_Preop ~ AgeAtInitialExam, \n                    data = complete_data)\n\n# Create prediction grid based on the range of non-missing age data\nprediction_data3 &lt;- tidyr::expand_grid(\n  AgeAtInitialExam = seq(min(complete_data$AgeAtInitialExam, na.rm = TRUE), \n                         max(complete_data$AgeAtInitialExam, na.rm = TRUE), \n                         length.out = 101)\n)\n\n# Create the plot using complete data\nFAOSPlot3 &lt;- ggplot(data = complete_data, \n                    mapping = aes(x = AgeAtInitialExam, y = FAOS_Pain_TotalScore_Preop)) + \n  geom_point(alpha = 0.5, color = \"steelblue\") +\n  # stat_lineribbon(\n  #   data = augment(FAOSlm_simple, newdata = prediction_data3, se_fit = TRUE),\n  #   aes(ydist = distributional::dist_student_t(df = df.residual(FAOSlm_simple), \n  #                              mu = .fitted, \n  #                              sigma = .se.fit)),\n  #   color = \"red\", fill = \"red\", alpha = 0.2, .width = 0.95) +\n  labs(y = \"FAOS Pain\")\n\n# Combine the plots\nFAOSPlot1 / FAOSPlot2 / FAOSPlot3\n\n\n\n\n\n\n\n\nFigure 7: FAOS Pain subscale Total Score by Diagnostic Group\n\n\n\n\n\n\n\nCode\nFAOSlm1 &lt;- lm(\n    FAOS_Pain_TotalScore_Preop ~ Sex2 * AgeAtInitialExam,\n    data = MasterAnalysis |&gt; dplyr::filter(!is.na(Sex2))\n)\n\n# Create the expanded grid manually\nprediction_data1 &lt;- tidyr::expand_grid(\n  Sex2 = unique(MasterAnalysis$Sex2[!is.na(MasterAnalysis$Sex2)]),\n  AgeAtInitialExam = seq(min(MasterAnalysis$AgeAtInitialExam, na.rm = TRUE), \n                         max(MasterAnalysis$AgeAtInitialExam, na.rm = TRUE), \n                         length.out = 101)\n)\n\n  FAOSlmFig &lt;- augment(FAOSlm1, newdata = prediction_data1, se_fit = TRUE) |&gt;\n  ggplot(aes(x = AgeAtInitialExam, fill = ordered(Sex2), color = ordered(Sex2))) +\n  stat_lineribbon(\n    aes(ydist = distributional::dist_student_t(df = df.residual(FAOSlm1), mu = .fitted, sigma = .se.fit)),\n    alpha = 1/4\n  ) +\n  #geom_point(aes(y = FAOS_Pain_TotalScore_Preop), data = MasterAnalysis) +\n  scale_fill_brewer(palette = \"Set2\") +\n  scale_color_brewer(palette = \"Dark2\") +\n  labs(\n    color = \"Sex2\",\n    fill = \"Sex2\",\n    y = \"FAOS_Pain_TotalScore_Preop\"\n  )\n\n\n\n\nCode\nFAOSlm2 &lt;- lm(\n    FAOS_Pain_TotalScore_Preop ~ Sex2 * SRCQTotalScore,\n    data = MasterAnalysis |&gt; dplyr::filter(!is.na(Sex2))\n)\n\n# Create the expanded grid manually\nprediction_data2 &lt;- tidyr::expand_grid(\n  Sex2 = unique(MasterAnalysis$Sex2[!is.na(MasterAnalysis$Sex2)]),\n  SRCQTotalScore = seq(min(MasterAnalysis$SRCQTotalScore, na.rm = TRUE), \n                         max(MasterAnalysis$SRCQTotalScore, na.rm = TRUE), \n                         length.out = 101)\n)\n\n  FAOSlmFig2 &lt;- augment(FAOSlm2, newdata = prediction_data2, se_fit = TRUE) |&gt;\n  ggplot(aes(x = SRCQTotalScore, fill = ordered(Sex2), color = ordered(Sex2))) +\n  stat_lineribbon(\n    aes(ydist = distributional::dist_student_t(df = df.residual(FAOSlm2), mu = .fitted, sigma = .se.fit)),\n    alpha = 1/4\n  ) +\n  #geom_point(aes(y = FAOS_Pain_TotalScore_Preop), data = MasterAnalysis) +\n  scale_fill_brewer(palette = \"Set2\") +\n  scale_color_brewer(palette = \"Dark2\") +\n  labs(\n    color = \"Sex2\",\n    fill = \"Sex2\",\n    y = \"FAOS_Pain_TotalScore_Preop\"\n  )\n  \n  knitr::knit_print(FAOSlmFig2)\n\n\n\n\n\n\n\n\n\nCorrelation matrix for FAOS subscales\n\n\nCode\nFAOSCorr &lt;- cor(MasterAnalysis |&gt; dplyr::select(contains(\"FAOS\")) |&gt; dplyr::rename(\n  Pain = \"FAOS_Pain_TotalScore_Preop\",\n  ADL = \"FAOS_DailyLiving_TotalScore_Preop\",\n  Symptoms = \"FAOS_Symptom_TotalScore_Preop\",\n  Sport = \"FAOS_Sport_TotalScore_Preop\",\n  QoL = \"FAOS_Quality_TotalScore_Preop\"\n),\n               use = \"pairwise.complete.obs\")\n\n\n\n\nCode\nFAOSCorrPlot &lt;- corrplot(FAOSCorr, method = \"number\")\n\nknitr::knit_print(FAOSCorrPlot)\n\n\n$corr\n          Symptoms      Pain       ADL     Sport       QoL\nSymptoms 1.0000000 0.6747166 0.6353669 0.5973797 0.5635241\nPain     0.6747166 1.0000000 0.8316436 0.6667254 0.6551129\nADL      0.6353669 0.8316436 1.0000000 0.7101361 0.6595432\nSport    0.5973797 0.6667254 0.7101361 1.0000000 0.6569004\nQoL      0.5635241 0.6551129 0.6595432 0.6569004 1.0000000\n\n$corrPos\n      xName    yName x y      corr\n1  Symptoms Symptoms 1 5 1.0000000\n2  Symptoms     Pain 1 4 0.6747166\n3  Symptoms      ADL 1 3 0.6353669\n4  Symptoms    Sport 1 2 0.5973797\n5  Symptoms      QoL 1 1 0.5635241\n6      Pain Symptoms 2 5 0.6747166\n7      Pain     Pain 2 4 1.0000000\n8      Pain      ADL 2 3 0.8316436\n9      Pain    Sport 2 2 0.6667254\n10     Pain      QoL 2 1 0.6551129\n11      ADL Symptoms 3 5 0.6353669\n12      ADL     Pain 3 4 0.8316436\n13      ADL      ADL 3 3 1.0000000\n14      ADL    Sport 3 2 0.7101361\n15      ADL      QoL 3 1 0.6595432\n16    Sport Symptoms 4 5 0.5973797\n17    Sport     Pain 4 4 0.6667254\n18    Sport      ADL 4 3 0.7101361\n19    Sport    Sport 4 2 1.0000000\n20    Sport      QoL 4 1 0.6569004\n21      QoL Symptoms 5 5 0.5635241\n22      QoL     Pain 5 4 0.6551129\n23      QoL      ADL 5 3 0.6595432\n24      QoL    Sport 5 2 0.6569004\n25      QoL      QoL 5 1 1.0000000\n\n$arg\n$arg$type\n[1] \"full\"\n\n\n\n\n\n\n\n\nFigure 8: Correlation matrix for FAOS subscales at baseline"
  },
  {
    "objectID": "SOFARI_Baseline.html#record-16-main-results",
    "href": "SOFARI_Baseline.html#record-16-main-results",
    "title": "Pain and function at baseline assessment of foot and ankle pathology: An analysis of the SOFARI Registry",
    "section": "4.4 RECORD [16] Main results",
    "text": "4.4 RECORD [16] Main results\n\nTable 4: Summary of regression assessing the effect of region on PCS-SF adjusted for confounders.\n\n\nCode\nFAOSPainfit1 &lt;- gtsummary::tbl_regression(\n  FAOSPainMod1,\n  tidy_fun = pool_and_tidy_mice,\n               label = list(\n                            Region ~ \"Diagnostic Group\"\n               ),\n  estimate_fun = function(x) style_number(x, digits = 2),\n  pvalue_fun = function(x) style_pvalue(x, digits = 3),\n  add_estimate_to_reference_rows = TRUE\n)\n\nFAOSSympfit1 &lt;- gtsummary::tbl_regression(\n  FAOSSympMod1,\n  tidy_fun = pool_and_tidy_mice,\n               label = list(\n                            Region ~ \"Diagnostic Group\"\n               ),\n  estimate_fun = function(x) style_number(x, digits = 2),\n  pvalue_fun = function(x) style_pvalue(x, digits = 3),\n  add_estimate_to_reference_rows = TRUE\n)\n\nFAOSADLfit1 &lt;- gtsummary::tbl_regression(\n  FAOSADLMod1,\n  tidy_fun = pool_and_tidy_mice,\n               label = list(\n                            Region ~ \"Diagnostic Group\"\n               ),\n  estimate_fun = function(x) style_number(x, digits = 2),\n  pvalue_fun = function(x) style_pvalue(x, digits = 3),\n  add_estimate_to_reference_rows = TRUE\n)\n\nFAOSSportfit1 &lt;- gtsummary::tbl_regression(\n  FAOSSportMod1,\n  tidy_fun = pool_and_tidy_mice,\n               label = list(\n                            Region ~ \"Diagnostic Group\"\n               ),\n  estimate_fun = function(x) style_number(x, digits = 2),\n  pvalue_fun = function(x) style_pvalue(x, digits = 3),\n  add_estimate_to_reference_rows = TRUE\n)\n\nFAOSQOLfit1 &lt;- gtsummary::tbl_regression(\n  FAOSQOLMod1,\n  tidy_fun = pool_and_tidy_mice,\n               label = list(\n                            Region ~ \"Diagnostic Group\"\n               ),\n  estimate_fun = function(x) style_number(x, digits = 2),\n  pvalue_fun = function(x) style_pvalue(x, digits = 3),\n  add_estimate_to_reference_rows = TRUE\n)\n\nFAOSfit1 &lt;- tbl_stack(list(\n  FAOSPainfit1,\n  FAOSSympfit1,\n  FAOSADLfit1,\n  FAOSSportfit1,\n  FAOSQOLfit1\n),\ngroup_header = c(\"Pain\", \"Symptoms\", \"ADL\", \"Sport\", \"Quality of Life\")\n)\n\nknitr::knit_print(FAOSfit1)\n\n\n\n\nTable 7: Summary of regression assessing the effect of region on FAOS unadjusted\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI\np-value\n\n\n\n\nPain\n\n\nDiagnostic Group\n\n\n\n\n\n\n\n\n    Ankle\n0.00\n—\n\n\n\n\n    Foot\n3.55\n-1.14, 8.25\n0.137\n\n\n    Forefoot\n7.86\n6.60, 9.13\n&lt;0.001\n\n\n    Midfoot\n0.88\n-0.79, 2.55\n0.299\n\n\n    Multiple\n0.98\n-0.34, 2.29\n0.145\n\n\n    Rearfoot\n0.32\n-1.80, 2.44\n0.767\n\n\nSymptoms\n\n\nDiagnostic Group\n\n\n\n\n\n\n\n\n    Ankle\n0.00\n—\n\n\n\n\n    Foot\n0.71\n-4.17, 5.58\n0.775\n\n\n    Forefoot\n12.70\n11.44, 13.96\n&lt;0.001\n\n\n    Midfoot\n5.71\n3.98, 7.43\n&lt;0.001\n\n\n    Multiple\n4.70\n3.43, 5.98\n&lt;0.001\n\n\n    Rearfoot\n6.42\n4.41, 8.42\n&lt;0.001\n\n\nADL\n\n\nDiagnostic Group\n\n\n\n\n\n\n\n\n    Ankle\n0.00\n—\n\n\n\n\n    Foot\n1.13\n-4.04, 6.30\n0.666\n\n\n    Forefoot\n8.70\n7.36, 10.05\n&lt;0.001\n\n\n    Midfoot\n0.82\n-0.99, 2.63\n0.371\n\n\n    Multiple\n2.08\n0.69, 3.47\n0.004\n\n\n    Rearfoot\n1.31\n-1.05, 3.66\n0.276\n\n\nSport\n\n\nDiagnostic Group\n\n\n\n\n\n\n\n\n    Ankle\n0.00\n—\n\n\n\n\n    Foot\n3.88\n-2.92, 10.67\n0.262\n\n\n    Forefoot\n15.35\n13.64, 17.05\n&lt;0.001\n\n\n    Midfoot\n4.21\n1.92, 6.50\n&lt;0.001\n\n\n    Multiple\n4.41\n2.78, 6.04\n&lt;0.001\n\n\n    Rearfoot\n5.14\n2.13, 8.14\n&lt;0.001\n\n\nQuality of Life\n\n\nDiagnostic Group\n\n\n\n\n\n\n\n\n    Ankle\n0.00\n—\n\n\n\n\n    Foot\n1.31\n-3.80, 6.43\n0.614\n\n\n    Forefoot\n10.97\n9.56, 12.38\n&lt;0.001\n\n\n    Midfoot\n2.82\n0.87, 4.77\n0.005\n\n\n    Multiple\n2.86\n1.49, 4.23\n&lt;0.001\n\n\n    Rearfoot\n2.19\n-0.43, 4.81\n0.100\n\n\n\nAbbreviation: CI = Confidence Interval\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nFAOSPainfit2 &lt;- gtsummary::tbl_regression(\n  FAOSPainMod2,\n  tidy_fun = pool_and_tidy_mice,\n               label = list(\n                            Region ~ \"Diagnostic Group\"\n               ),\n  estimate_fun = function(x) style_number(x, digits = 2), \n  pvalue_fun = function(x) style_pvalue(x, digits = 3)\n)  \n\nknitr::knit_print(FAOSPainfit2)\n\n\n\n\nTable 8: Summary of regression assessing the effect of region on FAOS adjusted for confounders\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI\np-value\n\n\n\n\nDiagnostic Group\n\n\n\n\n\n\n\n\n    Ankle\n—\n—\n\n\n\n\n    Foot\n5.64\n1.29, 10.00\n0.011\n\n\n    Forefoot\n7.83\n6.64, 9.03\n&lt;0.001\n\n\n    Midfoot\n1.11\n-0.46, 2.67\n0.166\n\n\n    Multiple\n1.68\n0.51, 2.86\n0.005\n\n\n    Rearfoot\n1.61\n-0.37, 3.59\n0.111\n\n\nAgeAtInitialExam\n0.00\n-0.03, 0.03\n0.982\n\n\nSex2\n\n\n\n\n\n\n\n\n    Female\n—\n—\n\n\n\n\n    Male\n1.08\n0.12, 2.04\n0.028\n\n\nBilateralPres\n\n\n\n\n\n\n\n\n    Index\n—\n—\n\n\n\n\n    Simultaneous\n2.94\n-4.04, 9.93\n0.404\n\n\n    Subsequent\n2.62\n-7.13, 12.37\n0.593\n\n\n    Unilateral\n3.60\n-3.13, 10.32\n0.290\n\n\nSRCQTotalScore\n-0.36\n-0.55, -0.16\n&lt;0.001\n\n\nVR12_Mental_TotalScore_Preop\n0.11\n0.06, 0.16\n&lt;0.001\n\n\nPCSSF_TotalScore_Preop\n-1.42\n-1.53, -1.32\n&lt;0.001\n\n\n\nAbbreviation: CI = Confidence Interval\n\n\n\n\n\n\n\n\n\n\n\nPredictions were generated from the model and summarised.\n\n\nCode\n# Calculate marginal means\nFAOSPainPredict &lt;- marginaleffects::predictions(\n  FAOSPainMod2,\n  type = \"response\"\n  ) \n\n\n\n\nCode\nFAOSPainPlot2 &lt;- ggplot(data = FAOSPainPredict, mapping = aes(y = Region, x = FAOS_Pain_TotalScore_Preop)) + stat_slabinterval(aes(thickness = after_stat(pdf*n)), scale = 0.7) +\n  stat_dotsinterval(side = \"bottom\", scale = 0.7, slab_linewidth = NA) +\n  scale_fill_brewer(palette = \"Set2\")\n\nknitr::knit_print(FAOSPainPlot2)\n\n\n\n\n\n\n\n\nFigure 9: Model predicted FAOS-Pain compared between diagnostic groups - region labels\n\n\n\n\n\nTable 5: Pairwise comparisons between regions for model-predicted averages of PCS-SF.\n\n\nCode\nFAOSPainComp &lt;- avg_comparisons(\n  FAOSPainMod2,\n  variables = list(Region = \"pairwise\"),\n  conf_level = 0.95\n) |&gt; dplyr::select(\n    contrast,\n    estimate,\n    std.error,\n    p.value\n    ) |&gt; gt() |&gt; fmt_number(\n    decimals = 3\n  )\n\n\nknitr::knit_print(FAOSPainComp)\n\n\n\n\nTable 9: Pairwise comparisons between regions for model-predicted averages of FAOS Pain\n\n\n\n\n\n\n\n\n\ncontrast\nestimate\nstd.error\np.value\n\n\n\n\nFoot - Ankle\n5.643\n2.207\n0.011\n\n\nForefoot - Ankle\n7.832\n0.607\n0.000\n\n\nForefoot - Foot\n2.189\n2.210\n0.323\n\n\nMidfoot - Ankle\n1.105\n0.796\n0.166\n\n\nMidfoot - Foot\n−4.538\n2.357\n0.056\n\n\nMidfoot - Forefoot\n−6.727\n0.818\n0.000\n\n\nMultiple - Ankle\n1.683\n0.594\n0.005\n\n\nMultiple - Foot\n−3.960\n2.264\n0.082\n\n\nMultiple - Forefoot\n−6.149\n0.627\n0.000\n\n\nMultiple - Midfoot\n0.578\n0.821\n0.482\n\n\nRearfoot - Ankle\n1.608\n1.005\n0.111\n\n\nRearfoot - Foot\n−4.035\n2.285\n0.079\n\n\nRearfoot - Forefoot\n−6.225\n1.053\n0.000\n\n\nRearfoot - Midfoot\n0.503\n1.108\n0.650\n\n\nRearfoot - Multiple\n−0.075\n1.071\n0.944"
  },
  {
    "objectID": "SOFARI_Baseline.html#record-17-other-analyses",
    "href": "SOFARI_Baseline.html#record-17-other-analyses",
    "title": "Pain and function at baseline assessment of foot and ankle pathology: An analysis of the SOFARI Registry",
    "section": "4.5 RECORD [17] Other analyses",
    "text": "4.5 RECORD [17] Other analyses"
  },
  {
    "objectID": "SOFARI_Baseline.html#record-18-key-results",
    "href": "SOFARI_Baseline.html#record-18-key-results",
    "title": "Pain and function at baseline assessment of foot and ankle pathology: An analysis of the SOFARI Registry",
    "section": "5.1 RECORD [18] Key results",
    "text": "5.1 RECORD [18] Key results"
  },
  {
    "objectID": "SOFARI_Baseline.html#record-19-limitations",
    "href": "SOFARI_Baseline.html#record-19-limitations",
    "title": "Pain and function at baseline assessment of foot and ankle pathology: An analysis of the SOFARI Registry",
    "section": "5.2 RECORD [19] Limitations",
    "text": "5.2 RECORD [19] Limitations\n\n\n5.2.1 RECORD [19.1] Implications of non-specific data"
  },
  {
    "objectID": "SOFARI_Baseline.html#record-20-interpretation",
    "href": "SOFARI_Baseline.html#record-20-interpretation",
    "title": "Pain and function at baseline assessment of foot and ankle pathology: An analysis of the SOFARI Registry",
    "section": "5.3 RECORD [20] Interpretation",
    "text": "5.3 RECORD [20] Interpretation"
  },
  {
    "objectID": "SOFARI_Baseline.html#record-21-generalisability",
    "href": "SOFARI_Baseline.html#record-21-generalisability",
    "title": "Pain and function at baseline assessment of foot and ankle pathology: An analysis of the SOFARI Registry",
    "section": "5.4 RECORD [21] Generalisability",
    "text": "5.4 RECORD [21] Generalisability"
  },
  {
    "objectID": "SOFARI_Baseline.html#record-22-funding",
    "href": "SOFARI_Baseline.html#record-22-funding",
    "title": "Pain and function at baseline assessment of foot and ankle pathology: An analysis of the SOFARI Registry",
    "section": "6.1 RECORD [22] Funding",
    "text": "6.1 RECORD [22] Funding"
  },
  {
    "objectID": "SOFARI_Baseline.html#record-23-accessibility-of-protocol-raw-data-and-programming-code",
    "href": "SOFARI_Baseline.html#record-23-accessibility-of-protocol-raw-data-and-programming-code",
    "title": "Pain and function at baseline assessment of foot and ankle pathology: An analysis of the SOFARI Registry",
    "section": "6.2 RECORD [23] Accessibility of protocol, raw data, and programming code",
    "text": "6.2 RECORD [23] Accessibility of protocol, raw data, and programming code\n\nProgramming code is incorporated into this document.\nStudy data may be accessed for reasonable research activities by contacting the corresponding author."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  }
]